{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 7.2 Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard\n",
    "In this section, we will introduce methods to allow our computationally involved models to become more self-aware and able to sense its environment, update its operator, and automatically make proactive corrections.\n",
    "\n",
    "## 7.2.1 Using callbacks to act ona model during training\n",
    "When training a model, there are many things you can't predict from the start. It's difficult to know how many epochs are necessary to get an optimal validation loss. In previous sections, we have trained models with enough epochs that we begin overfitting, using the first run to determine the proper number of epochs to train for, and then launching a new training run from scratch using the optimal number. So many unnecessary computations!\n",
    "\n",
    "A better approach would be to stop training when we measure the validation loss is no longer improving, which can be done using a Keras *callback*. A *callback* is an object that is passed to the model in the call to `fit`. The callback has the capability of interrupting training, saving a model, loading a different weight set, or altering the model in other ways. Here are some examples of ways to use callbacks:\n",
    " - **Model checkpointing** - Saving the current weights of the model at different points during training.\n",
    " - **Early stopping** - Interrupting training when the validation loss is no longer improving.\n",
    " - **Dynamically adjusting the value of parameters during training** - Such as the learning rate of the optimizer.\n",
    " - **Logging training and validation metrics during training, or visualizing representations learned by the model as they are updated** - The Keras progress bar is a callback!\n",
    " \n",
    "Let's review a few of the built-in callbacks from the `keras.callbacks` module:\n",
    "\n",
    "`keras.callbacks.ModelCheckpoint\n",
    "keras.callbacks.EarlyStopping\n",
    "keras.callbacks.LearningRateScheduler\n",
    "keras.callbacks.ReduceLROnPlateau\n",
    "keras.callbacks.CSVLogger`\n",
    "\n",
    "**THE ModelCheckpoint AND EarlyStopping CALLBACKS**\n",
    "\n",
    "We can use **`EarlyStopping`** to interrupt training once a target metric being monitored has stopped improving for a fixed number of epochs. For instance, this callback allows us to interrupt training as soon as we start overfitting, allowing us to avoid retraining our model for a smaller number of epochs. This callback is typically used in combination with **`ModelCheckpoint`**, which lets us continually save the model during training (and, optionally, save only the current best model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# Callbacks are passed to the model via the callbacks argument in fit\n",
    "# It takes a list of callbacks & we can pass any number of them.\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping( # interrupts training when improvement stops     \n",
    "        monitor='acc', # monitors model validation accuracy\n",
    "        patience=1, # interrupts training when acc has stopped improving for more than 1 epoch\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint( # Saves current weights after every epoch\n",
    "        filepath='my_model.h5', # Saves current weights after every epoch\n",
    "        monitor='val_loss', # Don't overwrite model unless val_loss has improved\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc']) # monitor accuracy, so it should be part of model's metrics\n",
    "\n",
    "model.fit(x, y,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val)) # need to pass validation_data to the call to fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THE ReduceLROnPlateau CALLBACK**\n",
    "\n",
    "We can use this callback to reduce the learning rate when the validation loss has stopped improving. Reducing or increasing the learning rate in case of a *loss plateau* is an effective strategy to get out of local minima during training. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss' # monitors model's validation loss\n",
    "        factor=0.1, # divides learning rate by 10 when triggered\n",
    "        patience=10, # triggered after validation loss has stopped improving for 10 epochs\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(x, y,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WRITING YOUR OWN CALLBACK**\n",
    "\n",
    "We can also implement our own callbacks if one of the built-in callbacks doesn't perform a specific action. Callbacks are implemented by subclassing the class `keras.callbacks.Callback`. We can implement any number of the following transparently names methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "on_epoch_begin # Called at start of every epoch\n",
    "on_epoch_end # Called at end of every epoch\n",
    "\n",
    "on_batch_begin # Called right before processing each batch\n",
    "on_batch_end # Called right after processing each batch\n",
    "\n",
    "on_train_begin # Called at the start of training\n",
    "on_train_end # Called at the end of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods all are called with a **`logs`** argument, which is a dictionary containing information about the previous batch, epoch, or training run: training and validation metrics, and so on. Additionally, the callback has access to the following attributes:\n",
    " - **`self.model`** - The model instance from which the callback is being called\n",
    " - **`self.model`** - The value of what was passed to `fit` as validation data\n",
    " \n",
    "Here is a simple example of a custom callback that saves to disk (as Numpy arrays) the activations of every layer of the model at the end of every epoch, computed on the first sample of the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model # called by parent model before training, to inform callback of what model will be calling it\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input,\n",
    "                                                    layer_outputs) # model instance that returns activations of every layer\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "\n",
    "        validation_sample = self.validation_data[0][0:1] # obtains the first input sample of validation data\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        f = open('activations_at_epoch_' + str(epoch) + '.npz', 'w')   # saves arrays to disk  \n",
    "        np.savez(f, activations)                                         \n",
    "        f.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.2 Introduction to TensorBoard: the TensorFlow visualization framework\n",
    "To do good research or develop good models, we need rich, frequent feedback about what’s going on inside our models during experiments. Making progress is an iterative process, or loop: start with an idea and express it as an experiment, attempt to validate or invalidate the idea. Run the experiment and process the information it generates, which inspires the next idea. The more iterations of this loop we’re able to run, the more refined and powerful our ideas become. Keras helps us go from idea to experiment in the least possible time, and fast GPUs can help get from experiment to result as quickly as possible. But what about processing the experiment results? That’s where TensorBoard comes in.\n",
    "\n",
    "![progress loop](images/7_2_2_progress.jpg)\n",
    "\n",
    "TensorBoard is a browser-based visualization tool that comes packaged with TensorFlow. The main purpose of TensorBoard is to help visually monitor everything that goes on inside a model during training. Several cool features are provided by TensorBoard, all in a browser:\n",
    " - Visually monitoring metrics during training\n",
    " - Visualizing model architecture\n",
    " - Visualizing histograms of activations and gradients\n",
    " - Exploring embeddings in 3D\n",
    " \n",
    "Let's take a look at these features with a simple example. We will train a 1D CNN on the IMDB sentiment-analysis task.\n",
    "\n",
    "**TEXT-CLASSIFICATION MODEL TO USE WITH TENSORBOARD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras modules\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of words to consider as features\n",
    "max_features = 2000\n",
    "\n",
    "# Cuts off texts after this number of words\n",
    "max_len = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128, input_length=max_len, name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use TensorBoard, we need to create a directory (my_log_dir) where we'll store the log files it generates. Once this is done, let's launch the training with a `TensorBoard` callback instance. This callback will write log events to disk at the specified location.\n",
    "\n",
    "**TRAINING THE MODEL WITH A TensorBoard CALLBACK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 136s - loss: 0.5878 - acc: 0.6993 - val_loss: 0.8700 - val_acc: 0.6854\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 139s - loss: 0.4796 - acc: 0.7954 - val_loss: 0.4303 - val_acc: 0.8108\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 145s - loss: 0.4000 - acc: 0.7792 - val_loss: 0.4723 - val_acc: 0.7696\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 137s - loss: 0.3552 - acc: 0.7556 - val_loss: 0.5212 - val_acc: 0.7258\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 144s - loss: 0.3043 - acc: 0.7167 - val_loss: 0.9554 - val_acc: 0.5748\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 143s - loss: 0.2727 - acc: 0.6734 - val_loss: 0.8029 - val_acc: 0.5650\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 139s - loss: 0.2430 - acc: 0.6167 - val_loss: 0.7546 - val_acc: 0.5358\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 138s - loss: 0.2030 - acc: 0.5648 - val_loss: 0.7529 - val_acc: 0.4640\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 151s - loss: 0.1859 - acc: 0.5060 - val_loss: 0.7807 - val_acc: 0.4516\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 146s - loss: 0.1486 - acc: 0.4482 - val_loss: 1.0505 - val_acc: 0.3544\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 164s - loss: 0.1334 - acc: 0.3844 - val_loss: 0.9945 - val_acc: 0.3428\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 139s - loss: 0.1335 - acc: 0.3399 - val_loss: 1.0136 - val_acc: 0.3200\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 138s - loss: 0.1207 - acc: 0.2848 - val_loss: 1.0464 - val_acc: 0.3032\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 138s - loss: 0.1210 - acc: 0.2449 - val_loss: 1.5016 - val_acc: 0.2570\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 139s - loss: 0.1223 - acc: 0.2142 - val_loss: 1.1289 - val_acc: 0.2522\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 138s - loss: 0.1129 - acc: 0.1871 - val_loss: 1.1423 - val_acc: 0.2502\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 138s - loss: 0.1175 - acc: 0.1641 - val_loss: 1.1852 - val_acc: 0.2194\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 138s - loss: 0.1148 - acc: 0.1518 - val_loss: 1.2193 - val_acc: 0.2086\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 138s - loss: 0.1136 - acc: 0.1304 - val_loss: 1.2049 - val_acc: 0.2194\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 140s - loss: 0.1130 - acc: 0.1244 - val_loss: 1.2683 - val_acc: 0.2024\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='my_log_dir', # files written here\n",
    "        histogram_freq=1, # Records activation histograms every 1 epoch\n",
    "        embeddings_freq=1, # Records embedding data every 1 epoch\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=20, batch_size=128,\n",
    "                    validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we can launch the TensorBoard server from the command line, instructing it to read the logs the callback is currently writing. Here is the command to enter:\n",
    "\n",
    "`tensorboard --logdir=my_log_dir`\n",
    "\n",
    "We can then browse to http://localhost:6006 and look at the model we are training. In addition to live graphs of the training and validation metrics, we can acced the Histograms tab where we can find pretty visualizations of histograms of activation values taken by our layers.\n",
    "\n",
    "![metrics](images/7_2_2_tensorboard1.jpg)\n",
    "![histograms](images/7_2_2_tensorboard2.jpg)\n",
    "\n",
    "The Embeddings tab gives us a way to inspect the embedding locations and spatial relationships of the 10,000 words in the input vocabulary, as learned by the initial `Embedding` layer. Because the embedding space is 128-dimensional, TensorBoard automatically reduces it to 2D or 3D using a dimensionality-reduction algorithm of choice: either principal component analysis (PCA) or t-distributed stochastic neighbor embedding (t-SNE). \n",
    "\n",
    "![clusters](images/7_2_2_tensorboard3.jpg)\n",
    "\n",
    "In figure above, in the point cloud, we can clearly see two clusters: words with a positive connotation and words with a negative connotation. The visualization makes it immediately obvious that embeddings trained jointly with a specific objective result in models that are completely specific to the underlying task—that’s the reason using pretrained generic word embeddings is rarely a good idea.\n",
    "\n",
    "![graphs](images/7_2_2_tensorboard4.jpg)\n",
    "\n",
    "The Graphs tab shows an interactive visualization of the graph of low-level TensorFlow operations underlying our Keras model. As you can see, there’s a lot more going on than you would expect. The model we just built may look simple when defined in Keras—a small stack of basic layers—but under the hood, we need to construct a fairly complex graph structure to make it work. A lot of it is related to the gradient-descent process. This complexity differential between what we see and what we’re manipulating is the key motivation for using Keras as our way of building models, instead of working with raw TensorFlow to define everything from scratch. Keras makes our workflow dramatically simpler.\n",
    "\n",
    "## Wrapping up\n",
    " - Keras callbacks provide a simple way to monitor models during training and automatically take action based on the state of the model.\n",
    " - When using TensorFlow, TensorBoard is a great way to visualize model activity in your browser. You can use it in Keras models via the TensorBoard callback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
