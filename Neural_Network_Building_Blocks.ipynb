{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The mathematical building blocks of neural networks\n",
    "Understanding deep learning requires an understanding of many simple mathematical concepts: tensors, tensor operations, differentiation, gradient descent, and more.\n",
    "\n",
    "## 2.1 A first look at a neural network\n",
    "Let's take a look at a neural network that classifies handwritten digits. The problem we're trying to solve is to classify grayscale images of handwritten digits (28 x 28 pixels) into their 10 categories (0 through 9). To do this, we will use the MNIST dataset which consists of 60,000 training images and 10,000 test images.\n",
    "\n",
    "#### Loading the MNIST dataset in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11264000/11490434 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_images` and `train_labels` form the training set, which is the data the model will learn from. The model will then be tested on the test set, which consists of `test_images` and `test_labels`. The images are encoded as Numpy arrays, and the labels are an array of digits, ranging from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view train data\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view test data\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow will be as follows: First, we will feed the neural network the training data. The network will then learn to associate images and labels. Then, we will ask the network to produce predictions for `test_images` and will see how well those predictions matched the actual `test_labels`.\n",
    "\n",
    "Now, let's build the network.\n",
    "#### The network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core building block of a neural network is the *layer*, which is effectively a filter for the data. Data goes in and comes out in a more useful representation. Most deep learning consists of chaining together multiple simple layers that will implement a form of progressive *data distillation*.\n",
    "\n",
    "The network we programmed above consists of two `Dense` layers, which are also called *fully connected*. The last layer is a 10-way *softmax* layer, which means it will return an array of 10 probability scores- each score corresponding to a number 0 to 9.\n",
    "\n",
    "To make the network ready for training, we need to pick three more things, as part of the *compilation* step:\n",
    " - A *loss function* - How the network will be able to measure its performance on the training data, and how it will be able to steer itself in the right direction.\n",
    " - An *optimizer* - The mechanism through which the network will update itself based on the data it sees and its loss function.\n",
    " - *Metrics to monitor during training and testing* - Here, we will only care about accuracy.\n",
    " \n",
    "#### The compilation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, we will reshape the data into the shape the network expects, and we will scale it so that all the pixel values are in the [0,1] interval.\n",
    "\n",
    "#### Preparing the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to categorically encode the labels.\n",
    "\n",
    "#### Preparing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 7s - loss: 0.3056 - acc: 0.9120     \n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 7s - loss: 0.2913 - acc: 0.9159     \n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 9s - loss: 0.2794 - acc: 0.9196     \n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.2691 - acc: 0.922 - 7s - loss: 0.2687 - acc: 0.9226     \n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 7s - loss: 0.2585 - acc: 0.9252     \n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 7s - loss: 0.2489 - acc: 0.9280     \n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 7s - loss: 0.2391 - acc: 0.9313     \n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 7s - loss: 0.2300 - acc: 0.9339     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a22fc13d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the network\n",
    "network.fit(train_images, train_labels, epochs=8, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two quantities are displayed during the training: the loss of the network over the training data, and the accuracy of the network over the training data.\n",
    "\n",
    "We were able to reach an accuracy of 93.4%, so now let's see how well the model performs on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9760/10000 [============================>.] - ETA: 0stest_acc:  0.9005\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)\n",
    "print \"test_acc: \", test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy turned out to be just over 90%, which is considerably lower than the training set accuracy. The gap in accuracies is an example of *overfitting*.\n",
    "\n",
    "## 2.2 Data representations for neural networks\n",
    "In the example above, we started with data stored in a multidimensional NumPy array, also called *tensors*. A tensor is a container for data- almost always numerical data. Matrices are 2D tensors: tensors are a generalization of matrices to an arbitrary number of dimensions.\n",
    "\n",
    "### 2.2.1 Scalars (0D tensors)\n",
    "A tensor that contains only one number is called a *scalar*. A scalar has 0 axes. The number of axes of a tensor is also called its *rank*. Here is a NumPy scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Vectors  (1D tensors)\n",
    "An array of numbers is called a *vector*, or 1D tensor. A 1D tensor is said to have exactly one axis. Here is a NumPy vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  3,  6, 14])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([12, 3, 6, 14])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This vector has five entries, so it is called a *5-dimensional vector*. A 5D vector has only one axis and has five dimensions along its axis, whereas a 5D tensor has five axes. *Dimensionality* can denote either number of entries along a specific axis or the number of axes in a tensor.\n",
    "\n",
    "### 2.2.3 Matrices (2D tensors)\n",
    "An array of vectors is a *matrix*, or 2D tensor. A matrix has two axes (rows and columns). Here is a NumPy matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[5, 78, 2, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 3D tensors and higher-dimensional tensors\n",
    "If you pack such matrices in a new array, you obtain a 3D tensor, which you can visually interpret as a cube of numbers. Here is a NumPy 3D tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]],\n",
    "              [[5, 78, 2, 34, 0],\n",
    "               [6, 79, 3, 35, 1],\n",
    "               [7, 80, 4, 36, 2]]])\n",
    "\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By packing 3D tensors in an array, you can create a 4D tensor, and so on. Deep learning generally consists of minipulating 0D to 4D tensors, but you may go up to 5D if you process video data.\n",
    "\n",
    "### 2.2.5 Key attributes\n",
    "A tensor is defined by three key attributes:\n",
    " - *Number of axes (rank)* - For instance, a 3D tensor has three axes, and a matrix has two axes. This is also called the tensor's `ndim` in Python libraries such as NumPy.\n",
    " - *Shape*- This is a tuple of integers that describes how many dimensions the tensor has along each axis. For instance, the previous matrix example has shape (3, 5), and the 3D tensor example has shape (3, 3, 5). A vector has a shape with a single element, such as (5,), and a scalar has an empty shape, ().\n",
    " - *Data type*- This is the type of the data contained in the tensor.\n",
    " \n",
    "To make this more concrete, let's look back at the data we processed in the MNIST example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we load the dataset\n",
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Next, display the number of axes of the tensor train_images\n",
    "print train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Here is the shape\n",
    "print train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# and Data type\n",
    "print train_images.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we have is a 3D tensor of 8-bit integers. Precisely, it's an array of 60,000 matrices of 28 x 8 integers. Each matrix is a grayscale image, with coefficients between 0 and 255.\n",
    "\n",
    "Let's display the 4th digit:\n",
    "\n",
    "#### Displaying the fourth digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQRF+IKj/AWrTQ8hNqS7JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a28d1e610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Manipulating tensors in Numpy\n",
    "Above, we *selected* a specific digit alongside the first axis. Selecting specific elements in a tensor is called *tensor slicing*. Here is an example of tensor slicing in NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent notation\n",
    "my_slice = train_images[10:100, :, :]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also equivalent notation\n",
    "my_slice = train_images[10:100, 0:28, 0:28]\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# can also use negative indices\n",
    "# crop image to a patch of 14x14 pixels centered in middle\n",
    "my_slice = train_images[:, 7:-7, 7:-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.7 The notion of data batches\n",
    "In general, the first axis in all data tensors you will come across in deep learning will be the *samples axis*. Deep learning models don't process an entire dataset at once; rather, they break the data into small batches. Here is one batch of the MNIST digits with batch size of 128:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = train_images[:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# next batch\n",
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nth batch\n",
    "n = 0\n",
    "batch = train_images[128 * n:128 * (n + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When considering a batch tenso, the first axis is called the *batch axis* or *batch dimension*.\n",
    "\n",
    "### 2.2.8 Real-world examples of data tensors\n",
    "Let's make data tensors more concrete with a few examples similar to what you'll encounter. The data you will manipulate will almost always fall into one of the following categories:\n",
    " - **Vector data** - 2D tensors of shape (`samples, features`)\n",
    " - **Timeseries data or sequence data**- 3D tensors of shape (`samples, timesteps, features`)\n",
    " - **Images** - 4D tensors of shape (`samples, height, width, channels`) or (`samples, channels, height width`)\n",
    " - **Video** - 5D tensors of shape (`samples, frames, height, width, channels`) or (`samples, frames, channels, height, width`)\n",
    " \n",
    "### 2.2.9 Vector data\n",
    "In the most common case, each point in a dataset can be encoded as a vector, and a batch of data will be encoded as a 2D tensor, where the first axis is the *samples axis* and the second axis is the *features axis*.\n",
    "Here are a few examples:\n",
    " - An actuarial dataset of people, where we consider each person's age, ZIP, and income. Each person can be characterized as a vector of 3 values. An entire dataset of 100,000 people can be stored in a 2D tensor of shape (100000, 3).\n",
    " - A dataset of text documents, where we represent each document by the counts of how many times each word appears in it (out of a dictionary of 20,000 common words). Each document can be encoded as a vector of 20,000 values (one counter per word in the dictionary). An entire dataset of 500 documents can be stored in a tensor of shape (500, 20000).\n",
    " \n",
    "### 2.2.10 Timeseries data or sequence data\n",
    "When time matters in your data (or the notion of sequence order), it makes sense to store it in a 3D tensor with an explicit time axis. Each sample can be encoded as a sequence of vectors (2D tensor). A batch of data will be encoded as a 3D tensor.\n",
    "\n",
    "![timeseries](images/2_2_10_timeseries.jpg)\n",
    "\n",
    "Time is always the second axis (index 1), by convention. Here are a few examples:\n",
    " - A dataset of stock prices. Every minute, we store the current price of the stock, the highest price in the past minute, and the lowest price in the past minute. Every minute is encoded as a 3D vector, an entire day of trading is encoded as a 2D tensor of shape (390, 3) (390 minutes in a trading day), and 250 days' worth of data can be stored in a 3D tensor of shape (250, 390, 3).\n",
    " - A dataset of tweets, where we encode each tweet as a sequence of 280 characters out of an alphabet of 128 unique characters. Each character can be encoded as a binary vector of size 128 (all zeros except for a 1 for the character). Then each tweet can be encoded as a 2D tensor of shape (280, 128), and a dataset of 1 million tweets can be stored in a tensor of shape (1000000, 280, 128).\n",
    " \n",
    "### 2.2.11 Image data\n",
    "Images usually have three dimensions: height, width, and color depth. Grayscale images only have a single color channel and could be stored in 2D tensor, but, by convention, most image tensors are always 3D, with a 1D color channel for grayscale images. A batch of 128 grayscale images of size 256 x 256 could be stored in a tensor of shape (128, 256, 256, 1), and a batch of 128 color images could be stored in a tensor of shape (128, 256, 256, 3).\n",
    "\n",
    "![imagetensor](images/2_2_11_imagetensor.jpg)\n",
    "\n",
    "There are two common conventions for shapes of image tensors: the *channels-last* convention (used by TensorFlow) and the *channels-first* convention (Theano). TensorFlow places color-depth axis at the end (`samples, height, width, color_depth`), while Theano places it after the batch axis (`samples, color_depth, height, width`). Keras supports both formulas.\n",
    "\n",
    "### 2.2.12 Video data\n",
    "Video data requires 5D tensors. A video can be understood as a sequence of frames, each frame being a color image. Because each frame is stored in a 3D tensor (height, width, color_depth), a sequence of frames can be stored in a 4D tensor (frames, height, width, color_depth), and a batch of different videos can be stored in a 5D tensor of shape (samples, frames, height, width, color_depth).\n",
    " - An example would be a 60-second, 144 x 256 video clip sampled at 4 frames per second would have 240 frames (60 x 4 = 240). A batch of four video clips would be stored in a tensor of shape (4, 240, 144, 256, 3). That's 106,168,320 values! If the datatype of the tensor was `float32`, then each value would be stored in 32 bits, so the tensor would be 405 MB. Luckily, most videos are compressed significantly (say, MPEG format).\n",
    " \n",
    "## 2.3 The gears of neural networks: tensor operations\n",
    "All transformations learned by deep neural networks can be reduced to a handful of *tensor operations* applied to tensors of numeric data.\n",
    "\n",
    "The example above built a network by stacking `Dense` layers on top of each other. A Keras layer looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.layers.Dense(512, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer is essentially a function that takes a 2D tensor as its input and returns another 2D tensor which is a new representation of the input tensor. Specifically, the finction is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W is a 2D tensor and b is a vector\n",
    "output = relu(dot(W, input) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function above, we have three tensor operations: a dot product between the input tensor and a tensor named W; an addition between the resulting 2D tensor and a vector b; and a `relu` operation which is `max(x, 0)`.\n",
    "\n",
    "### 2.3.1 Element-wise operations\n",
    "The `relu` operation and the addition are *element-wise* operations that are applied independently to each entry in the tensors being considered. This means the operations are good for massive parallel implementations. If you want to write a naive Python implementation of an element-wise operation, you would use a `for` loop, as in this naive implementation of an element-wise `relu` operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2  # x is a 2D Numpy tensor\n",
    "    \n",
    "    x = x.copy() # Avoid overwriting the input tensor\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 78,  0, 34,  0],\n",
       "       [ 6, 79,  3, 35,  1],\n",
       "       [ 7, 80,  4, 36,  2]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2D = np.array([[5, 78, -1, 34, 0],\n",
    "              [6, 79, 3, 35, 1],\n",
    "              [7, 80, 4, 36, 2]])\n",
    "naive_relu(tensor2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same for loop for addition\n",
    "def naive_add(x, y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    \n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you can do element-wise multiplication, subtraction, division, etc.\n",
    "\n",
    "### 2.3.2 Broadcasting\n",
    "The `naive_add` function above only supports the addition of 2D tensors with identical shapes. But in the `Dense` layer introduced earlier, we added a 2D tensor with a vector. What happens with addition when the shapes of the two tensors being added differ? When possible, the smaller tensor with be *broadcasted* to match the shape of the larger tensor.\n",
    "\n",
    "Consider X with a shape of (32, 10) and y with a shape of (10,). First, we add an empty first axis to y, whose shape becomes (1,10). Then we repeat y 32 times alongside this new axis, so that we end up with a tensor Y with shape (32,10), where Y[i,:] == y for i in range(0,32). At this point, we can proceed to add X and Y because they have the same shape.\n",
    "\n",
    "Here is a naive implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x, y):\n",
    "    assert len(x.shape) == 2 # 2D tensor\n",
    "    assert len(y.shape) == 1 # Numpy vector\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    \n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example applies the element-wise maximum operation to two tensors of different shapes via broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.random((64, 3, 32, 10))\n",
    "y = np.random.random((32, 10))\n",
    "\n",
    "z = np.maximum(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Tensor dot\n",
    "The dot operation (aka *tensor product*) is the most common, most useful tensor operation. An element-wise product is done with the * operator in Numpy, Keras, Theano, and TensorFlow. Here is how it is done in Numpy and Keras (different in TensorFlow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = np.dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Naive implementation of dot product of two vectors: x and y\n",
    "def naive_vector_dot(x, y):\n",
    "    assert len(x.shape) == 1 # x and y are numpy vectors\n",
    "    assert len(y.shape) == 1\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    \n",
    "    z = 0.\n",
    "    for i in range(x.shape[0]):\n",
    "        z += x[i] * y[i]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "naive_vector_dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function returns a scalar, which is the dot product between two vectors. You can also take the dot product between a matrix x and a vector y, which returns a vector where the coefficients are the dot products between y and the rows of x. Here is an implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_matrix_vector_dot(x, y):\n",
    "    assert len(x.shape) == 2 # x is numpy matrix\n",
    "    assert len(y.shape) == 1 # y is numpy vector\n",
    "    assert x.shape[1] == y.shape[0] # 1st dimension of x is same as 0th of y\n",
    "    \n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            z[i] += x[i, j] * y[j]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  50.,  122.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "\n",
    "y = np.array([7, 8, 9])\n",
    "\n",
    "naive_matrix_vector_dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# could also write function like this\n",
    "def naive_matrix_vector_dot(x, y):\n",
    "    z = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        z[i] = naive_vector_dot(x[i, :], y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As soon as one of the two tensors has an `ndim` greater than 1, `dot` is not longer symmetric, which means `dot(x,y)` is not the same as `dot(y,x)`.\n",
    "\n",
    "The most common applications may be the dot product between two matrices. You can take the dot product of two matrices x and y (dot(x,y)) if and only if x.shape[1] == y.shape[0]. The result is a matrix with shape (x.shape[0], y.shape[1]), where the coefficients are the vector products between the rows of x and columns of y. Here is the naive implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def naive_matrix_dot(x, y):\n",
    "    assert len(x.shape) == 2 # x is numpy matrix\n",
    "    assert len(y.shape) == 2 # y is numpy matrix\n",
    "    assert x.shape[1] == y.shape[0] # 1st dimension of x is same as 0th of y\n",
    "    \n",
    "    z = np.zeros((x.shape[0], y.shape[1])) # returns a matrix of 0s in shape given\n",
    "    for i in range(x.shape[0]): # iterates over rows of x\n",
    "        for j in range(y.shape[1]): # and columns of y\n",
    "            row_x = x[i, :] \n",
    "            column_y = y[:, j] \n",
    "            z[i, j] = naive_vector_dot(row_x, column_y)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.,  24.,  30.],\n",
       "       [ 48.,  66.,  84.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2],\n",
    "              [4, 5]])\n",
    "y = np.array([[2, 4, 6],\n",
    "              [8, 10, 12]])\n",
    "\n",
    "naive_matrix_dot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an image to better visualize the dot-product shape compatibility:\n",
    "\n",
    "![matrixdot](images/2_3_3_matrixdot.jpg)\n",
    "\n",
    "The rows of x and the columns of y must have the same shape.\n",
    "\n",
    "### 2.3.4 Tensor reshaping\n",
    "A third type of tensor operation that's essential to understand is *tensor reshaping*. This was used when we preprocessed the digits data before feeding it into our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping a tensor means rearranging its rows and columns to match a target shape. The reshaped tensor has the same total number of coefficients as the initial tensor. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0., 1.],\n",
    "              [2., 3.],\n",
    "              [4., 5.]])\n",
    "\n",
    "print x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 2.],\n",
       "       [ 3.],\n",
       "       [ 4.],\n",
       "       [ 5.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((6, 1))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.],\n",
       "       [ 3.,  4.,  5.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((2, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special case of reshaping that's commonly encountered is *transposition*. *Transposing* a matrix means exchanging its rows and columns, so that x[i, :] becomes x[:, i]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((300, 20))\n",
    "x = np.transpose(x)\n",
    "print x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Geometric interpretation of tensor operations\n",
    "The contents of manipulated tensors can be interpreted as coordinates of points in a geometric space. Let's consider addition. Start with the following vector: `A = [0.5, 1]`\n",
    "\n",
    "This is essentially a point in 2D space. It is common to picture a vector as an arrow linking the origin to the point (see below).\n",
    "\n",
    "![point](images/2_3_5_point.jpg)\n",
    "\n",
    "Now consider a new point, `B = [1, 0.25]` which we will add to the previous point. To add the two points, we must chain their vector arrows together, and the resulting location is a vector that represents the sum of the previous vectors.\n",
    "\n",
    "![point2](images/2_3_5_point2.jpg)\n",
    "\n",
    "### 2.3.6 A geometric interpretation of deep learning\n",
    "Neural networks consist entirely of chains of tensor operations and all of these tensor operations are just geometric transformations of the input data. A neural network is a very complex geometric transformation in a high-dimensional space, implemented in a long series of simple steps.\n",
    "\n",
    "A mental image might be useful here. Imagine two sheets of colored paper: one red and one blue. Put one piece on top of the other, and then crumple them together into a small ball. The crumpled paper ball in the input data, and each sheet of paper is a class of data in a classification problem. A neural network is used to figure out a transformation of the paper ball that uncrumples it, as to make the two classes cleanly separable.\n",
    "\n",
    "\n",
    "## 2.4 The engine of neural networks: gradient-based optimization\n",
    "In the implementation of the network above, each neural layer transforms its input data as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = relu(dot(W, input) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W and b are tensors that are attributes of the layer that are called *weights* or *trainable parameters* of the layer. These weights contain the information learned by the network from exposure to training data.\n",
    "\n",
    "To start, these weight matrices are filled with small random values, which, as one could guess, do not yield useful results from the start. What comes next is gradually adjusting these weights based on a feedback signal. This gradual adjustment, or *training*, is the learning that machine learning is all about. It all happens within what's called a *training loop*, which works as follows:\n",
    " 1. Draw a batch of training samples x and corresponding targets y.\n",
    " 2. Run the network on x to obtain predictions y_pred.\n",
    " 3. Compute the loss of the network on the batch, a measure of the mismatch between y_pred and y.\n",
    " 4. Update all weights of the network in a way that slightly reduces the loss on this batch.\n",
    " \n",
    "Eventually, you will end up with a network that has a very low loss on its training data, meaning a low mismatch rate between y_pred and the expected targets y. The difficult step in the process above is step 4: updating the network's weights. An efficient way to do this is to take advantage of the fact that all operations used in the network are *differentiable*, and compute the *gradient* of the loss with regard to the network's coefficients. You then move the coefficients in the opposite direction from the gradient, which decreases the loss.\n",
    "\n",
    "### 2.4.1 What's a derivative?\n",
    "Consider a continuous, smooth function $f(x) = y$, that maps a real number x to a new real number y. Because the function is continuous, a small change in x only results in a small change in y. Say you increase x by a small factor `epsilon_x`, which results in a small `epsilon_y` change to y:\n",
    "\n",
    "$f(x + epsilon_x) = y + epsilon_y$\n",
    "\n",
    "Because the function is also smooth (no sharp angles), when `epsilon_x` is small enough, at around a certain point `p`, it's possible to approximate `f` as a linear function of slope `a`, so that `epsilon_y` becomes `a * epsilon_x`:\n",
    "\n",
    "$f(x + epsilon_x) = y + a * epsilon_x$\n",
    "\n",
    "This linear approximation is only valid when x is close enough to p.\n",
    "\n",
    "The slope `a` is the derivative of `f` in `p`. If `a` is negative, it means a small change of `x` around `p` will result in a decrease in `f(x)`. Additionally, the absolute value of `a` tells you how quickly this increase or decrease will happen.\n",
    "\n",
    "![deriv](images/2_4_1_derivative.jpg)\n",
    "\n",
    "For every differentiable function `f(x)`, there exists a derivative function `f'(x)` that maps values of x to the slope of the local linear approximation of `f` in those points. \n",
    "\n",
    "If you are trying to update `x` by a factor of `epsilon_x` in order to minimize `f(x)`, you just need to move `x` a little in the opposite direction from the derivative.\n",
    "\n",
    "### 2.4.2 Derivative of a tensor operation: the gradient\n",
    "A *gradient* is the derivative of a tensor. Consider an input vector `x`, a matrix `W`, a target `y`, and a loss function `loss`. You can use `W` to compute a target candidate `y_pred`, and compute the loss between the target candidate `y_pred` and the target `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = dot(W, x)\n",
    "loss_value = loss(y_pred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data inputs x and y are frozen, then this can be interpreted as a function mapping values of `W` to loss values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_value = f(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative of a function `f(x)` of a single coefficient can be interpreted as the slope of the curve of `f`. You can reduce the value of `f(x)` by moving `x` a little in the opposite direction from the derivative.\n",
    "\n",
    "### 2.4.3 Stochastic gradient descent\n",
    "Given a differentiable function, it's theoretically possible to find its minimum analytically: it's known that a function's minimum is a point where the derivative is 0, so all you have to do is find all the points where the derivative goes to 0 and check for which of these points the function has the lowest value.\n",
    "\n",
    "Applied to a neural network, that means finding analytically the combination of weight values that yields the smallest possible loss function. This can be done by solving the equation `gradient(f)(W) = 0` for `W`. To do this, you can use a four-step algorithm to modify the parameters little by little based on the current loss value on a random batch of data. Because you are dealing with a differentiable function, you can compute its gradient, giving you an efficient way to implement step 4. By updating the weights in the opposite direction from the gradient, the loss will be a little less every time:\n",
    " 1. Draw a batch of training samples `x` and corresponding targets `y`.\n",
    " 2. Run the network on `x` to obtain predictions `y_pred`.\n",
    " 3. Compute the loss of the network on the batch, a measure of the mismatch between `y_pred` and `y`.\n",
    " 4. Compute the gradient of the loss with regard to the network's parameters (*backward pass*)\n",
    " 5. Move the parameters a little in the opposite direction from the gradient, thus reducing the loss on the batch a bit.\n",
    " \n",
    "The process above is known as *mini-batch stochastic gradient descent*. *Stochastic* refers to the randomness of each batch of data. Here is an image that further gives a visual to this process:\n",
    "\n",
    "![scd](images/2_4_3_scd.jpg)\n",
    "\n",
    "It's important to pick a reasonable value for the `step` factor. If it's too small, the descent down the curve will take make iterations, and it could get stuck in a local minimum. If it's too large, your updates may end up taking you to completely random locations on the curve.\n",
    "\n",
    "There exist several variations of SGD that differ by taking into account previous weight updates when computing the next weight update, rather than just looking at the gradients. One version is SGD with momentum which helps with convergence speed and avoiding local minima. A parameter being optimized via SGD with a small learning rate runs the risk of getting stuck in a local minimum instead of making its way to the global minimum. Momentum is implemented by updating the parameter *w* based not only on the current gradient value but also on the previous parameter update. Here is a naive implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_velocity = 0.\n",
    "momentum = 0.1\n",
    "while loss > 0.01:\n",
    "    w, loss, gradient = get_current_parameters()\n",
    "    velocity = past_velocity * momentum + learning_rate * gradient\n",
    "    w = w + momentum * velocity - learning_rate * gradient\n",
    "    past_velocity = velocity\n",
    "    update_parameter(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 Chaining derivatives: the Backpropagation algorithm\n",
    "In practice, a neural network function consists of many tensor operations chained together, each of which has a simple, known derivative. For example, this is a network *f* made up of three tensor operations, *a, b*, and *c*, with weight matrices *W1, W2*, and *W3*:\n",
    "\n",
    "$f(W1, W2, W3) = a(W1, b(W2, c(W3)))$\n",
    "\n",
    "Such a chain of functions can be derived using the chain rule: $f(g(x)) = f'(g(x)) * g'(x)$. Applying the chain rule to the computation of gradient values of a neural network leads us to the algorithm called *Backpropagation*. Backpropagation starts with the final loss value and works backward from the top layers to the bottom layers, applying the chain rule to compute the contribution that each parameter ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
