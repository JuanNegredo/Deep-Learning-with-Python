{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 6 Deep learning for text and sequences\n",
    "\n",
    "This section explore deep learning models that can process text, timeseries, and sequence data in general. The two fundamental deep learning algorithms for sequence processing are ***recurrent neural networks*** and ***1D convenets***, which is a one dimensional version of 2D convnets. Applications of these algorithms include:\n",
    " - Document classification and timeseries classification, such as identifying the topic of an article or author of a book.\n",
    " - Timeseries comparisons, such as estimating how closely related two documents or two stock tickers are.\n",
    " - Sequence-to-sequence learning, such as decoding an English sentence into French.\n",
    " - Sentiment analysis, such as classifying the sentiment of tweets or movie reviews as positive or negative.\n",
    " - Timeseries forecasting, such as predicting the future weather at a certain location, given recent weather data.\n",
    " \n",
    "## 6.1 Working with text data\n",
    "Text can be unstood as either a sequence of characters or a sequence of words, but working with words is most common. Deep learning for natural language processing is pattern recognition applied to words, sentences, and paragraphs, in much the same way that computer vision is pattern recognition applied to pixels.\n",
    "\n",
    "Deep learning models don't take raw text as input; they only work with numeric tensors. ***Vectorizing*** text is the process of transforming text into numeric tensors, and it can be done in multiple ways:\n",
    " - Segment text into words, and transform each word into a vector.\n",
    " - Segment text into characters, and transform each n-gram into a vector.\n",
    " - Extract n-grams of words or characters, and transform each n-gram into a vector. *N-grams* are overlapping groups of multiple consecutive words or characters.\n",
    " \n",
    "The different units we can break text into are called ***tokens***, and breaking text into tokens is called ***tokenization***. There are two major ways to associate a vector with a token: *one-hot encoding* of tokens, and *token embedding*.\n",
    "\n",
    "![text token vector](images/6_1_0_text.jpg)\n",
    "\n",
    "**UNDERSTANDING N-GRAMS AND BAG-OF-WORDS**\n",
    "Word n-grams are groups of N (or fewer) consecutive words that you can extract from a sentence. The same concept may also be applied to letters.\n",
    "\n",
    "Here is a simple example. Consider the sentence *\"The cat sat on the mat.\"* It may be decomposed into the following set of 2-grams:\n",
    "\n",
    "`{\"The\",\"The cat\",\"cat\",\"cat sat\",\"sat\",\"sat on\",\"on\",\"on the\",\"the\",\"the mat\",\"mat\"}`\n",
    "\n",
    "It may also be decomposed into a set of 3-grams:\n",
    "\n",
    "`{\"The\",\"The cat\",\"cat\",\"cat sat\",\"The cat sat\",\"sat\",\"sat on\",\"on\",\"cat sat on\",\n",
    "  \"on the\",\"the\",\"sat on the\",\"the mat\",\"mat\",\"on the mat\"}`\n",
    "  \n",
    "The above sets are called a *bag-of-2-grams* or *bag-of-3-grams*, respectively. The term bag refers to the fact that we are dealing with a set of tokens rather than a list or sequence: the tokens have no specific order. This family of tokenization methods is called *bag-of-words*.\n",
    "\n",
    "Because bag-of-words isn't an order-preserving tokenization method, it tends to be used in shallow language-processing models rather than in deep learning models. Extracting n-grams is a form of feature engineering, and deep learning does away with this kind of rigid, brittle approach, replacing it with hierarchical feature learning. 1D convnets and RNNs are capable of learning representations for groups of words and characters without being explicitly told about the existence of such groups, by looking at continuous word or character sequences. \n",
    "\n",
    "### 6.1.1 One-hot encoding of words and characters\n",
    "One-hot encoding is the most common, most basic way to turn a token into a vector.\n",
    "\n",
    "Let's look at an example of one-hot encoding with words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# initial data. One entry per sample\n",
    "samples = ['The cat sat on the mat.', 'The dog at my homework.']\n",
    "\n",
    "# Build an index of all tokens in data\n",
    "token_index = {}\n",
    "for sample in samples:\n",
    "    for word in sample.split():\n",
    "        if word not in token_index:\n",
    "            token_index[word] = len(token_index) + 1\n",
    "            \n",
    "# Vectorizes the samples. Only consider first 10 words            \n",
    "max_length = 10\n",
    "\n",
    "# Store results\n",
    "results = np.zeros(shape=(len(samples), max_length, max(token_index.values()) + 1))\n",
    "\n",
    "for i, samples in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = token_index.get(word)\n",
    "        results[i, j, index] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an example of one-hot encoding with characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\r",
      "\u000b",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "characters = string.printable # all printable ASCII characters\n",
    "token_index = dict(zip(range(1, len(characters) + 1), characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "characters = string.printable # all printable ASCII characters\n",
    "token_index = dict(zip(range(1, len(characters) + 1), characters))\n",
    "\n",
    "max_length = 50\n",
    "results = np.zeros((len(samples), max_length, max(token_index.keys()) + 1))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, character in enumerate(sample):\n",
    "        index = token_index.get(character)\n",
    "        results[i, j, index] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we did it the hard way, let's observe how Keras has built-in utilities for doing one-hot encoding of text at the word level or character level, starting with raw text data. These utilities are useful because they strip special characters from strings and only take the *N* most common words into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "# create a tokenizer to take only most 1000 common words\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "\n",
    "# build the word index\n",
    "tokenizer.fit_on_texts(samples)\n",
    "\n",
    "# turn strings into lists of integer indices\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
    "\n",
    "# recover word index\n",
    "word_index = tokenizer.word_index\n",
    "print \"Found %s unique tokens.\" % len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ate': 7,\n",
       " 'cat': 2,\n",
       " 'dog': 6,\n",
       " 'homework': 9,\n",
       " 'mat': 5,\n",
       " 'my': 8,\n",
       " 'on': 4,\n",
       " 'sat': 3,\n",
       " 'the': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HASHING TRICK**\n",
    "\n",
    "A variant of one-hot encoding is the *one-hot hashing trick*, which you can use when the number of unique tokens in your vocabulary is too large to handle explicitly. Instead of explicitly assigning an index to each word and keeping a reference of these indices in a dictionary, you can hash words into vectors of fixed size. The advantage of this method is that it does away with maintaining an explicit word index, which saves memory and allows online encoding of the data. The one drawback is that this method is susceptible to *hash collisions*: two different words may end up with the same hash.\n",
    "\n",
    "Let's see a code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
    "\n",
    "# Stores the words as vectors of size 1000\n",
    "dimensionality = 1000\n",
    "max_length = 10\n",
    "\n",
    "results = np.zeros((len(samples), max_length, dimensionality))\n",
    "for i, sample in enumerate(samples):\n",
    "    for j, word in list(enumerate(sample.split()))[:max_length]:\n",
    "        index = abs(hash(word)) % dimensionality\n",
    "        results[i, j, index] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Using word embeddings\n",
    "Another popular and powerful way to associate a vector with a word is the use of dense ***word vectors***, aka ***word embeddings***. While vectors obtained through one-hot encoding are binary, sparse, and very high-dimensional, word embeddings are low-dimensional floating-point vectors. Unlike word vectors obtained via one-hot encoding, word embeddings are learned from data. It's common to see word embeddings that are 512-dimensional, or 1,024-dimensional when dealing with very large vocabularies, but one-hot encoding words generally lead to vectors that are 20,000-dimensional or greater. Word embeddings pack more information into far fewer dimensions.\n",
    "\n",
    "![word embeddings](images/6_1_2_embeddings.jpg)\n",
    "\n",
    "There are two ways to obtain word embeddings:\n",
    " - Learn word embeddings jointly with the main task you care about (such as document classification or sentiment prediction). In this setup, you start with random word vectors and then learn word vectors in the same way you learn the weights of a neural network.\n",
    " - Load word embeddings into your model that were precomputed using a different machine learning task than the one you're trying to solve. These are called *pretrained word embeddings*.\n",
    " \n",
    "Let's dive deeper into both:\n",
    "\n",
    "**LEARNING WORD EMBEDDINGS WITH THE EMBEDDING LAYER**\n",
    "\n",
    "The simplest way to associate a dense vector with a word is to choose the vector at random. The problem with this approach is that the resulting embedding space has no structure: for instance, the words *accurate* and *exact* may end up with completely different embeddings, even though they're interchangeable in most sentences. It's difficult for a deep neural network to make sense of such a noisy, unstructured embedding space.\n",
    "\n",
    "Word embeddings are meant to map human language into a geometric space. In a reasonable embedding space, you would expect synonyms to be embedded into similar word vectors, and words meaning different things are embedded at points far away from each other, whereas related words are closer. Let's look at an example.\n",
    "\n",
    "![word embedding example](images/6_1_2_space.jpg)\n",
    "\n",
    "In the image about, four words are embedded on a 2D plane: *cat, dog, wolf,* and *tiger*. With the vector representations we chose here, some semantic relationships between these words can be encoded as geometric transformations. For instance, the same vector allows us to go from *cat* to *tiger* and from *dog* to *wolf*: this vector could be interpreted as the \"from pet to wild animal\" vector. Another vector could allow us to go from *dog* to *cat* and from *wolf* to *tiger*, which could be interpreted as a \"from canine to feline\" vector.\n",
    "\n",
    "In real-world word-embedding spaces, common examples of meaningful geometric transformations are \"gender\" vectors and \"plural\" vectors. For instance, by adding a \"femal\" vector to the vector \"king,\" we obtain the vector \"queen\". By adding a \"plural\" vector, we obtain \"kings\". \n",
    "\n",
    "What makes a good word-embedding space depends heavily on your task: the perfect word-embedding space for an English-language movie-review sentiment analysis model may look different from the perfect embedding space for an English-language legal-document-classification model, because the importance of certain semantic relationships varies from task to task. Thus, it's reasonable to learn a new embedding space with every new task. Fortunately, backpropagation makes this easy, and Keras makes it even easier. It's about learning the weights of an **`Embedding`** layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "# Embedding layer takes two arguments: number of possible tokens & dimen. of embeddings\n",
    "embedding_layer = Embedding(1000, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`Embedding`** layer is best understood as a dictionary that maps interger indices (words) to dense vectors. It takes integers as its input, looks up these integers in an internal dictionary, and then returns the associated vectors. \n",
    "\n",
    "The **`Embedding`** layer takes a 2D tensor of integers as an input, of shape (`samples, sequence_length`), where each entry is a sequence of integers. All sequences in a batch must have the same length, so sequences that are shorter than others should be padded with zeros, and longer sequences should be truncated.\n",
    "\n",
    "This layer returns a 3D floating-point tensor of shape (`samples, sequence_length, embedding_dimensionality`). This tensor can be processed by an RNN layer or a 1D convolution layer.\n",
    "\n",
    "Let's apply this idea to the IMDB movie-review sentiment-prediction task. We will quickly prepare the data by restricting the movie reviews to the top 10,000 most common words and cut off the reviews after only 20 words. The network will learn 8-dimensional embeddings for each of the 10,000 words, turn the input integer sequences (2D integer tensor) into embedded sequences (3D float tensor), flatten the tensor to 2D, and train a single `Dense` layer on top for classification.\n",
    "\n",
    "**LOADING IMDB DATA FOR USE WITH EMBEDDING LAYER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "# number of words to consider as features\n",
    "max_features = 10000\n",
    "\n",
    "# cut off text after this many words\n",
    "maxlen = 20\n",
    "\n",
    "# load data as list of integers\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# turn list of integers into a 2D integer tensor of shape (samples, maxlen)\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USING EMBEDING LAYER AND CLASSIFIER ON IMDB DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# specify max input length to embedding layer so we can later flatten embedded inputs\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add classifier on top\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.6685 - acc: 0.6234 - val_loss: 0.6174 - val_acc: 0.6938\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.5389 - acc: 0.7539 - val_loss: 0.5247 - val_acc: 0.7316\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.4580 - acc: 0.7928 - val_loss: 0.5014 - val_acc: 0.7478\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.4186 - acc: 0.8104 - val_loss: 0.4951 - val_acc: 0.7518\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.3915 - acc: 0.8250 - val_loss: 0.4958 - val_acc: 0.7536\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.3697 - acc: 0.8375 - val_loss: 0.5003 - val_acc: 0.7512\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.3502 - acc: 0.8503 - val_loss: 0.5062 - val_acc: 0.7502\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.3321 - acc: 0.8602 - val_loss: 0.5135 - val_acc: 0.7498\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.3146 - acc: 0.8701 - val_loss: 0.5218 - val_acc: 0.7470\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 2s - loss: 0.2981 - acc: 0.8786 - val_loss: 0.5295 - val_acc: 0.7452\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a validation accuracy of ~75%, which isn't bad considering we are only looking at the first 20 words of each review. By merely flattening the embedded sequences and training a single `Dense` layer on top leads to a model that treats each word in the input sequence separately, without considering inter-word relationships and sentence structure (\"this movie is the bomb\" vs. \"this movie was a bomb\"). It's better to add recurrent layers or 1D convolutional layers on top of the embedded sequences to learn features that take each sequence as a whole into account.\n",
    "\n",
    "**USING PRETRAINED WORD EMBEDDINGS**\n",
    "Sometimes, you have so little training data available that you can't use your data alone to learn an appropriate task-specific embedding of your vocabulary. What do you do then?\n",
    "\n",
    "Instead of learning word embeddings jointly with the problem you want to solve, you can load embedding vectors from precomputed embedding space that you know if highly structures and exhibits useful properties that capture generic aspects of language structure. \n",
    "\n",
    "Such word embeddings are generally computed using word-occurrence statistics, using a variety of techniques, some involving neural networks, others not. There are various precomputed databases of word embeddings that you can download and use in a Keras `Embedding` layer. Word2vec is one of them. Another popular one is called Global Vectors for Word Representation (GLoVE).\n",
    "\n",
    "### 6.1.3 Putting it all together: from raw text to word embeddings\n",
    "We'll use a model similar to the one above: embedding sentences in sequences of vectors, flattening them, and training a `Dense` layer on top. But we'll do so using pretrained word embeddings. And instead of using the pretokenized IMDB data packaged in Keras, we will start from scratch using raw text data.\n",
    "\n",
    "**DOWNLOADING THE IMDB DATA AS RAW TEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = '/Volumes/RobStorage/Desktop/Python_Practice/DL_with_Python/data/IMDB/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TOKENIZING THE DATA**\n",
    "\n",
    "Let's vectorize the text and prepare a training and validation split. Because pretrained word embeddings are meant to be particularly useful on problems where little training data is available, we'll restrict the training data to the first 200 samples. Our model will learn to classify movie reviews are looking at **just 200 samples**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88584 unique tokens.\n",
      "Shape of data tensor: (25000, 100)\n",
      "Shape of label tensor: (25000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Cut off reviews after 100 words\n",
    "maxlen = 100\n",
    "\n",
    "# Trains on 200 samples\n",
    "training_samples = 200\n",
    "\n",
    "# Validates on 10,000 samples\n",
    "validation_samples = 10000\n",
    "\n",
    "# Consider only top 10,000 words in dataset\n",
    "max_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print \"Found %s unique tokens.\" % len(word_index)\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print \"Shape of data tensor:\", data.shape\n",
    "print \"Shape of label tensor:\", labels.shape\n",
    "\n",
    "# Split data into a training & validation set\n",
    "# Shuffle data first because samples are all negative first\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DOWNLOAD GLoVE WORD EMBEDDINGS**\n",
    "\n",
    "The GLoVE word embeddings contain 100-dimensional embedding vectors for 400,000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_dir = '/Volumes/RobStorage/Desktop/Python_Practice/DL_with_Python/data/IMDB/glove.6B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPROCESSING THE EMBEDDINGS**\n",
    "\n",
    "Let's parse the unzipped file to build an index that maps words (as strings) to their vector representation (as number vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print \"Found %s word vectors.\" % len(embeddings_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build an embedding matrix that we can load into an `Embedding` layer. It must be a matrix of shape (`max_words, embedding_dim`). Note that index 0 is a placeholder and isn't supposed to stand for any word or token.\n",
    "\n",
    "**PREPARING THE GLoVE WORD-EMBEDDINGS MATRIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector # words not found in embedding = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINE A MODEL**\n",
    "We will use the same model architecture as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOADING THE GLoVE EMBEDDINGS IN THE MODEL**\n",
    "The `Embedding` layer has a single weight matrix: a 2D float matrix where each entry $i$ is the word vector meant to be associated with index $i$. Let's load the GLoVE matrix we prepared into the `Embedding` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also freeze the `Embedding` layer (trainable = False). When parts of a model are pretrained (like our `Embedding` layer) and parts are randomly initialized (like our classifier), the pretrained parts shouldn't be updated during training, to avoid forgetting what they already know.\n",
    "\n",
    "**TRAINING AND EVALUATING THE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s - loss: 2.0330 - acc: 0.5150 - val_loss: 0.7080 - val_acc: 0.5280\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s - loss: 0.5197 - acc: 0.7500 - val_loss: 0.9988 - val_acc: 0.5016\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s - loss: 0.4037 - acc: 0.8550 - val_loss: 0.7129 - val_acc: 0.5466\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s - loss: 0.3290 - acc: 0.8650 - val_loss: 1.0471 - val_acc: 0.5001\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s - loss: 0.2387 - acc: 0.9400 - val_loss: 0.7075 - val_acc: 0.5710\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s - loss: 0.1135 - acc: 1.0000 - val_loss: 1.1586 - val_acc: 0.5030\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s - loss: 0.2337 - acc: 0.9000 - val_loss: 0.7440 - val_acc: 0.5673\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s - loss: 0.0554 - acc: 1.0000 - val_loss: 0.9359 - val_acc: 0.5327\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s - loss: 0.0437 - acc: 1.0000 - val_loss: 1.3408 - val_acc: 0.5095\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s - loss: 0.3593 - acc: 0.8400 - val_loss: 0.7893 - val_acc: 0.5665\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "\n",
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXUQkgv4fqWKL+iiTENQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a26b6eb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a317f2e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model's performance over time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model begins overfitting almost from the start, which makes sense because we only used 200 training samples. The validation accuracy seems to reach high 50%, which isn't ideal. Because we have so few training samples, performance is heavily dependent on exactly which 200 samples we choose.\n",
    "\n",
    "We can also try training the same model without loading the pretrained word embeddings and without freezing the embedding layer. Doing this, we will learn a task-specific embedding of the input tokens, which is generally more powerful than pretrained word embeddings when lots of data is available. Let's try this method:\n",
    "\n",
    "**TRAINING SAME MODEL WITHOUT PRETRAINED WORD EMBEDDINGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s - loss: 0.6898 - acc: 0.4800 - val_loss: 0.6927 - val_acc: 0.5232\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 1s - loss: 0.5005 - acc: 0.9850 - val_loss: 0.7037 - val_acc: 0.5329\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 1s - loss: 0.2923 - acc: 0.9900 - val_loss: 0.7211 - val_acc: 0.5352\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 1s - loss: 0.1330 - acc: 0.9900 - val_loss: 0.7107 - val_acc: 0.5242\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 1s - loss: 0.0658 - acc: 1.0000 - val_loss: 0.7191 - val_acc: 0.5373\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 1s - loss: 0.0314 - acc: 1.0000 - val_loss: 0.7297 - val_acc: 0.5365\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 1s - loss: 0.0176 - acc: 1.0000 - val_loss: 0.7387 - val_acc: 0.5374\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 1s - loss: 0.0100 - acc: 1.0000 - val_loss: 0.7483 - val_acc: 0.5377\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 1s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.7565 - val_acc: 0.5384\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 1s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.7627 - val_acc: 0.5397\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a31d7c410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a31e28690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model's performance over time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation accuracy stalls in the low 50s. In this case, pretrained word embeddings outperform jointly learned embeddings. If we increase the number of training samples, this will quickly stop being the case.\n",
    "\n",
    "Finally, let's evaluate the model on the test data. First, we need to tokenize the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24576/25000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8004352753829956, 0.56004]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and evaluate the first model\n",
    "model.load_weights('pre_trained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes! We got a terrible test accuracy of **56%**. Working with just a handfull of training samples is difficult. We will consider this a lesson learned, and will attempt improved strategies in the next section.\n",
    "\n",
    "At this point, we are able to do the following:\n",
    " - **Turn raw text into something a neural network can process**\n",
    " - **Use the `Embedding` layer in a Keras model to learn task-specific token embeddings**\n",
    " - **Use pretrained word embeddings to get an extra boost on small NLP problems**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
