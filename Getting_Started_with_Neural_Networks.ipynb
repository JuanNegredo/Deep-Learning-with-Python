{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with neural networks\n",
    "## 3.1 Anatomy of a neural network\n",
    "Training a neural network revolves around the following objects:\n",
    " - **Layers**, which are combined into a network (or model)\n",
    " - The **input data** and corresponding **targets**.\n",
    " - The **loss function**, which defines the feedback signal used for learning.\n",
    " - The **optimizer**, which determines how learning proceeds.\n",
    " \n",
    "The network, composed of layers that are chained together, maps the input data to predictions. The loss function then compares these predictions to the targets, producing a loss value which is a measure of how well the network's predictions match the target values. The optimizer uses the loss function to update the network's weights and repeat the process.\n",
    "\n",
    "### 3.1.1 Layers: the building blocks of deep learning\n",
    "The fundamental data structure in neural networks is the layer, which is a data-processing module that takes one or more tensors as inputs, and outputs one or more tensors. The layer's generally have a state, defined by the layer's weights which contain the network's knowledge.\n",
    "\n",
    "Different layers are appropriate for different tensor formats and different data types. For instance, simple vector data, stored in 2D tensors of shape (`samples, features`), is often processed by *densely connected* layers. Sequence data, stored in 3D tensors of shape (`samples, timesteps, features`) is typically processed by *recurrent* layers such as an `LSTM` layer. Image data, stored in 4D tensors, is usually processed by 2D convolution layers (`Conv2D`).\n",
    "\n",
    "Layers are basically the LEGO bricks of deep learning. Building deep learning models in Keras is done by clipping together compatible layers to form useful data-transformation pipelines. Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "layer = layers.Dense(32, input_shape=(784,)) # dense layer with 32 output units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above layer will only accept 2D tensors as input where the first dimension is 784. This layer will return a tensor where the first dimension has been transformed to be 32. This layer can only be connected to a downstream layer that expects 32-dimensional vectors as its input. Keras dynamically builds layers to match the shape of the incoming layer. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second layer didn't receive an input shape argument, but it inferred its input shape as being the output shape of the previous layer.\n",
    "\n",
    "### 3.1.2 Models: networks of layers\n",
    "A deep-learning model is a directed, acyclic graph of layers. The most common instance is a linear stack of layers, mapping a single input to a single output.\n",
    "\n",
    "The topology of a network defines a *hypothesis space*. By choosing a network topology, you constrain your space of possibilities to a specific series of tensor operations, mapping input data to output data. \n",
    "\n",
    "### 3.1.3 Loss functions and optimizers: keys to configuring the learning process\n",
    "Once the network architecture is defined, you still have to choose two more things:\n",
    " - **Loss function** - The quantity that will be minimized during training.\n",
    " - **Optimizer**- Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent.\n",
    " \n",
    "Choosing the right loss function for the right problem is extremely important. Fortunately, when it comes to common problems such as classification, regression, and sequence prediction, there are simple guidelines to follow to choose the correct loss. \n",
    "\n",
    "## 3.2 Introduction to Keras\n",
    "Keras is a deep learning framework for Python that provides a convenient way to define and train almost any kind of deep learning model.\n",
    "\n",
    "### 3.2.2 Developing with Keras: a quick overview\n",
    "The typical Keras workflow looks like this:\n",
    " 1. Define your training data: input tensors and target tensors.\n",
    " 2. Define a network of layers (or model) that maps your inputs to your targets.\n",
    " 3. Configure the learning process by choosing a loss function, an optimizer, and some metrics to monitor.\n",
    " 4. Iterate on your training data by calling the `fit()` method of your model.\n",
    " \n",
    "There are two ways to define a model: using the `Sequential` class (most common, only for linear layers) or the functional API (for directed acyclic graphs of layers).\n",
    "\n",
    "Here is a two-layer model defined using the `Sequential` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(784,)))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same model using the functional API\n",
    "input_tensor = layers.Input(shape=(784,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=input_tensor, outputs=output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the functional API, you are manipulating the data tensors that the model processes and applying layers to this tensor as if they were functions.\n",
    "\n",
    "Once your model architecture is defined, it doesn't matter whether you used a `Sequential` or `functional API` model. The learning process is configured in the compilation step, where you specify the optimizer and loss function(s) that the model should use, as well as the metrics you want to monitor during training. Here is an example with a single loss function (most common case):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the learning process consists of passing Numpy arrays of input data to the model via the `fit()` method, similar to Scikit-Learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(input_tensor, target_tensor, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
