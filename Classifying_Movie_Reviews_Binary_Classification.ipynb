{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying movie reviews: a binary classification example\n",
    "In this example we will create a binary classifier to classify movie reviews as either positive or negative based on text of the reviews.\n",
    "\n",
    "### 3.4.1 The IMDB dataset\n",
    "We will work with the IMDB dataset which consists of 50,000 highly polarized reviews from IMDB. The data is split into 25,000 reviews for training and 25,000 for testing, each consisting of 50% negative and 50% positive reviews. The IMDB dataset comes packaged with Keras and has already been processed: the reviews (sequence of words) have been turned into sequences of integers where each integer stands for a specific word in a dictionary.\n",
    "\n",
    "Let's load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17448960/17464789 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument `num_words` means we will only keep the 10,000 most frequently occurring words in the training data. This allows us to work with vector data of manageable size. \n",
    "\n",
    "The variables `train_data` and `test_data` are lists of reviews; each is a list of word indices (encoding a sequence of words). `train_labels` and `test_labels` are lists of 0s and 1s, where 0 is **negative** and 1 is **positive**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 14,\n",
       " 22,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 4,\n",
       " 173,\n",
       " 36,\n",
       " 256,\n",
       " 5,\n",
       " 25,\n",
       " 100,\n",
       " 43,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 9,\n",
       " 35,\n",
       " 480,\n",
       " 284,\n",
       " 5,\n",
       " 150,\n",
       " 4,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 39,\n",
       " 4,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 17,\n",
       " 546,\n",
       " 38,\n",
       " 13,\n",
       " 447,\n",
       " 4,\n",
       " 192,\n",
       " 50,\n",
       " 16,\n",
       " 6,\n",
       " 147,\n",
       " 2025,\n",
       " 19,\n",
       " 14,\n",
       " 22,\n",
       " 4,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 4,\n",
       " 22,\n",
       " 71,\n",
       " 87,\n",
       " 12,\n",
       " 16,\n",
       " 43,\n",
       " 530,\n",
       " 38,\n",
       " 76,\n",
       " 15,\n",
       " 13,\n",
       " 1247,\n",
       " 4,\n",
       " 22,\n",
       " 17,\n",
       " 515,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 626,\n",
       " 18,\n",
       " 2,\n",
       " 5,\n",
       " 62,\n",
       " 386,\n",
       " 12,\n",
       " 8,\n",
       " 316,\n",
       " 8,\n",
       " 106,\n",
       " 5,\n",
       " 4,\n",
       " 2223,\n",
       " 5244,\n",
       " 16,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 33,\n",
       " 4,\n",
       " 130,\n",
       " 12,\n",
       " 16,\n",
       " 38,\n",
       " 619,\n",
       " 5,\n",
       " 25,\n",
       " 124,\n",
       " 51,\n",
       " 36,\n",
       " 135,\n",
       " 48,\n",
       " 25,\n",
       " 1415,\n",
       " 33,\n",
       " 6,\n",
       " 22,\n",
       " 12,\n",
       " 215,\n",
       " 28,\n",
       " 77,\n",
       " 52,\n",
       " 5,\n",
       " 14,\n",
       " 407,\n",
       " 16,\n",
       " 82,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 107,\n",
       " 117,\n",
       " 5952,\n",
       " 15,\n",
       " 256,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3766,\n",
       " 5,\n",
       " 723,\n",
       " 36,\n",
       " 71,\n",
       " 43,\n",
       " 530,\n",
       " 476,\n",
       " 26,\n",
       " 400,\n",
       " 317,\n",
       " 46,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 1029,\n",
       " 13,\n",
       " 104,\n",
       " 88,\n",
       " 4,\n",
       " 381,\n",
       " 15,\n",
       " 297,\n",
       " 98,\n",
       " 32,\n",
       " 2071,\n",
       " 56,\n",
       " 26,\n",
       " 141,\n",
       " 6,\n",
       " 194,\n",
       " 7486,\n",
       " 18,\n",
       " 4,\n",
       " 226,\n",
       " 22,\n",
       " 21,\n",
       " 134,\n",
       " 476,\n",
       " 26,\n",
       " 480,\n",
       " 5,\n",
       " 144,\n",
       " 30,\n",
       " 5535,\n",
       " 18,\n",
       " 51,\n",
       " 36,\n",
       " 28,\n",
       " 224,\n",
       " 92,\n",
       " 25,\n",
       " 104,\n",
       " 4,\n",
       " 226,\n",
       " 65,\n",
       " 16,\n",
       " 38,\n",
       " 1334,\n",
       " 88,\n",
       " 12,\n",
       " 16,\n",
       " 283,\n",
       " 5,\n",
       " 16,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 32,\n",
       " 15,\n",
       " 16,\n",
       " 5345,\n",
       " 19,\n",
       " 178,\n",
       " 32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no word index should exceed 10,000\n",
    "max([max(sequence) for sequence in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 2s     \n"
     ]
    }
   ],
   "source": [
    "# decode review back to English\n",
    "word_index = imdb.get_word_index() #dictionary mapping words to integer index\n",
    "\n",
    "# this reverses the dictionary so we return words instead of numbers\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# This decodes the review. Note indices are offset by 3 because 0, 1, & 2 are...\n",
    "# reserved indices for \"padding,\" \"start of sequence,\" and \"unknown\"\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Preparing the data\n",
    "You can't feed lists of integers into a neural network. You must turn your lists into tensors. There are two ways to do that:\n",
    " - Pad lists so they all have the same length, turn them into an integer tensor of shape (`samples, word_indices`), and then use the first layer in the network as a layer capable of handling such integer tensors (the `Embedding` layer).\n",
    " - **OR** One-hot encode the lists to turn them into vectors of 0s and 1s. This would mean turning the sequence [`3, 5`] into a 10,000-dimensional vector that would be all 0s except for indices 3 and 5, which would be 1s. Then you could use the first layer as a `Dense Layer`, capable of handling floating-point vector data.\n",
    " \n",
    "We will go with the 2nd option of vectorizing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension)) # creates an all-zero matrix\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1. # Sets specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "# vectorize training data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "\n",
    "# vectorize testing data\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  1., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What do samples look like now?\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also vectorize the labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is ready to be fed into a neural network!\n",
    "\n",
    "### 3.4.3 Building the network\n",
    "The input data is vectors and the labels are scalars (1s and 0s). A type of network that performs well on this type of problem is a simple stack of fully connected (Dense) layers with `relu` activations.\n",
    "\n",
    "The argument being passed to each `Dense` layer (16) is the number of hidden units of the layer. A *hidden unit* is a dimension in the representation space of the layer. Having 16 hidden units means the weight matrix `W` will have shape (`input_dimension, 16`): the dot product with `W` will project the input data onto a 16-dimensional representation space. The dimensionality of representation space is basically \"how much freedom you're allowing the network to have when learning internal representations.\" More hidden units allows the network to learn more-complex representations, but the network becomes more computationally expensive and may lead to overfitting.\n",
    "\n",
    "For this model, we will use:\n",
    " - Two intermediate layers with 16 hidden units each\n",
    " - A third layer will output the scalar prediction regarding the sentiment of the current review\n",
    " \n",
    "The intermediate layers will use `relu` activation function, and the final layer will use a sigmoid activation so the output is a probability indicating how likely a sample is to have the target \"1\".\n",
    "\n",
    "##### Rectified linear unit function\n",
    "![relu](images/3_4_3_relu.jpg)\n",
    "\n",
    "##### Sigmoid function\n",
    "![sigmoid](images/3_4_3_sigmoid.jpg)\n",
    "\n",
    "##### Our three-layer network\n",
    "![network](images/3_4_3_network.jpg)\n",
    "\n",
    "\n",
    "Here is the Keras implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to choose a loss function and an optimizer. Because we are facing a binary classification problem and the output of the network is a probability, it's best to use `binary_crossentropy` loss. Here, we will configure the model with the `rmsprop` optimizer and the `binary_crossentropy` loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may want to configure the parameters of your optimizer which can be done by passing an optimizer class instance at the `optimizer` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001), \n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you may want to pass a custom loss function or metric function, which can be done by passing function objects as the `loss` and/or `metrics` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "              loss=losses.binary_crossentropy, \n",
    "              metrics=[metrics.binary_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 Validating approach\n",
    "To monitor the accuracy of the model during training on data it has never seen before, we will create a validation set by setting apart 10,000 samples from the original training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the model for 20 epochs in mini-batches of 512 samples. We will also monitor the loss and accuracy on the 10,000 samples that we set apart. We do this by passing the validation data as the `validation_data` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 6s - loss: 0.5157 - acc: 0.7895 - val_loss: 0.4008 - val_acc: 0.8656\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 6s - loss: 0.3146 - acc: 0.9030 - val_loss: 0.3247 - val_acc: 0.8789\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 3s - loss: 0.2319 - acc: 0.9246 - val_loss: 0.2808 - val_acc: 0.8924\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.1816 - acc: 0.9431 - val_loss: 0.2729 - val_acc: 0.8907\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.1496 - acc: 0.9514 - val_loss: 0.2780 - val_acc: 0.8888\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.1210 - acc: 0.9632 - val_loss: 0.3226 - val_acc: 0.8804\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.1031 - acc: 0.9689 - val_loss: 0.3045 - val_acc: 0.8847\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0848 - acc: 0.9761 - val_loss: 0.3361 - val_acc: 0.8771\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0729 - acc: 0.9805 - val_loss: 0.3592 - val_acc: 0.8801\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0583 - acc: 0.9862 - val_loss: 0.3718 - val_acc: 0.8800\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0492 - acc: 0.9884 - val_loss: 0.3978 - val_acc: 0.8774\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0389 - acc: 0.9919 - val_loss: 0.4410 - val_acc: 0.8773\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0303 - acc: 0.9944 - val_loss: 0.4530 - val_acc: 0.8745\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0245 - acc: 0.9958 - val_loss: 0.4805 - val_acc: 0.8735\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0203 - acc: 0.9968 - val_loss: 0.5572 - val_acc: 0.8697\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0124 - acc: 0.9995 - val_loss: 0.5493 - val_acc: 0.8727\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0128 - acc: 0.9982 - val_loss: 0.5776 - val_acc: 0.8709\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0088 - acc: 0.9989 - val_loss: 0.6068 - val_acc: 0.8671\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0071 - acc: 0.9993 - val_loss: 0.6423 - val_acc: 0.8660\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s - loss: 0.0065 - acc: 0.9990 - val_loss: 0.6758 - val_acc: 0.8676\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acc', 'loss', 'val_acc', 'val_loss']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to `model.fit()` returns a `History` object that stores a dictionary containing data about everything that happened during training. The dictionary contains four entries: one per metric being measured during training and validation. Now let's plot the training and validation loss side by side, and then the training and validation side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8igpiIhIHiUFERHJo6QgIiJ5/j9CIU8t1EajzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2207b4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(history_dict['acc']) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecVOXZ//HPtRSRXoUIyhI1SpHmBgUrYkFNQKwoNgwh\n8Fhj9JGISYyJz8/4Mz7GEgwaURRBLKiJokZjAvlZQelFEFelSpNqYdnr98d9dpldtpzd2ZnZZb/v\n1+u8ZubUa87OzjXnvu9z3+buiIiIlCcr0wGIiEjNoIQhIiKxKGGIiEgsShgiIhKLEoaIiMSihCEi\nIrEoYUgsZlbHzLab2cFVuW4mmdmhZpaSduXF921mr5vZsFTEYWa/MrOHKru9SFxKGPuo6Au7YMo3\ns68TXpf4xVUWd9/t7o3d/fOqXLe6MrM3zOzXJcw/18xWmVmdiuzP3U9z90lVENcpZpZbbN+/c/dR\nye67nGO6mf0iVceQmkEJYx8VfWE3dvfGwOfAjxPm7fXFZWZ10x9ltfY4cGkJ8y8FnnT33WmOJ5Mu\nBzYBl6X7wPpcVi9KGLWUmf3ezJ42s8lmtg24xMz6mtm7ZvaVma0xs/vMrF60ft3oV2Z29PrJaPl0\nM9tmZu+YWaeKrhstP8PMPjazLWZ2v5n9PzO7opS448T4MzNbbmabzey+hG3rmNn/mtlGM1sBDCzj\nFD0PtDOzfgnbtwLOBCZGrweZ2Rwz22pmn5vZr8o43/8peE/lxWFmI8xscXSuPjGzEdH8ZsDfgIMT\nrhYPiP6WjyVsP8TMFkbn6J9mdnjCspVmdoOZzY/O92Qz26+MuJsA5wD/BXQxs57Flp8Q/T22mNkX\nZnZpNL9h9B4/j5bNMLP9SrpCimI6KXpeoc9ltM2R0RXhJjNba2b/bWbtzWynmTVPWK9PtFxJqLLc\nXdM+PgG5wCnF5v0e+A74MeGHw/7AD4GjgbrA94GPgauj9esCDmRHr58ENgA5QD3gacIv74quewCw\nDRgcLbsB2AVcUcp7iRPji0AzIJvwy/iUaPnVwEKgA9AKmBH+BUo9bxOAhxJeXwXMSnh9MtA1On89\novf4o2jZoYn7Bv5T8J7KiyP6m3wfsOgYXwPdo2WnALkl/C0fi553BrZH29UDbgGWAvWi5SuBd4F2\n0bE/BkaUcQ6GR9tkAdOB/01Y1ik61gXRuW8N9IyW/QV4E/geUAc4LoqnpPhXAidV8nPZDFgHXAfs\nBzQF+kTLXgd+mnCc+xPj11SJ75JMB6ApDX/k0hPGP8vZ7kbgmeh5SUkg8ct0ELCgEuteCcxMWGbA\nGkpJGDFjPCZh+fPAjdHzGYlfjoSrBS9j3ycREs5+0ev3gGvKWP8B4P9Gz8tKGBWN4+/AVdHz8hLG\nb4GnEpZlAWuB46LXK4GhCcvvAR4o49j/Au6Onl8afTnXjV7/quDcF9umDvAt0LWEZXESRkU+l5cC\nH5Sy3jDg3wmfjfVA76r+/6pNk4qkarcvEl+Y2RFm9nJ02b4VuJ3wq7E0axOe7wQaV2LdAxPj8PDf\nvbK0ncSMMdaxgM/KiBfg38BW4Mdm9gOgFzA5IZa+ZvYvM1tvZluAESXEUpIy4zCzH5nZe1ERy1fA\naTH3W7Dvwv25ez7hfLZPWCfW3y0qUjwBKKjzmhatW1CEdhDwSQmbtgXql7Isjop8LkuLoSDeHhZa\n6w0EvnT3DysZk6A6jNqueFPOvwALgEPdvSnwa8Iv/lRaQyiaAcDMjKJfbsUlE+MawhdMgTKb/UbJ\nayKhsvdS4BV335CwyhTgOeAgd28GPBIzllLjMLP9gWeB/wO0dffmhKKVgv2W1/x2NdAxYX9ZhPO7\nKkZcxV0WHXe6ma0FlhMSweXR8i+AQ0rYbh2hWKmkZTuAhgnx1SUUjSWqyOeytBhw952Ev88wwt/v\niZLWk/iUMCRRE2ALsMPMOgM/S8Mx/w70NrMfR18e1wFtUhTjVOD6qEK0FXBzjG0mEn6dXkloOVU8\nlk3u/o2ZHQMMrYI49iN8Ka8HdpvZj4ABCcvXAa2jyujS9j3IzE6KKoZvItQRvRcztkSXEb6ceyZM\nFxKuuFoQihoHWmhqXNfMWptZDw8tyB4D7jWzdlEl/7FRPEuAJmZ2evT6N4S6jbKU9Td/idAI4Oqo\nUr2pmfVJWD6R8Lc7K4pXkqCEIYl+Qfj1uI3wq+7pVB/Q3dcRvoTuATYSfi1+RCgDr+oYxxEqYucD\nHxB+yZcX33LgfcIX+cvFFo8G/k/UmucWwpd1UnG4+1fAzwnFKZuA8whJtWD5AsKv5tyo1dABxeJd\nSDg/4whJZyAwyN13xYwNADM7jlC89aC7ry2YorhygQvd/VNC5fTNUawfAkdGu/g5sBiYHS37H8Dc\nfTNwDSH5roqWJRaRlaTUv7m7bwFOBc4lJNOPgRMTtp1BqL94z91LLeqUeCyqEBKpFizcELcaOM/d\nZ2Y6Hqn5zGwG8Ki7P5bpWGo6XWFIxpnZQDNrHt0P8CtCs9r3MxyW7AOiosJuwDOZjmVfoIQh1cFx\nwApCEcrpwBB3L61ISiQWM5sEvApc5+47Mh3PvkBFUiIiEouuMEREJJZ9qk+V1q1be3Z2dqbDEBGp\nMWbPnr3B3ctqyl5on0oY2dnZzJo1K9NhiIjUGGZWXo8HhVQkJSIisShhiIhILEoYIiISixKGiIjE\nooQhIiKxpCxhmNmjZvalmS0oZblFQy0uN7N5ZtY7YdlAM1saLRuTqhhFpGabNAmysyErKzxO2mu0\n+uqtpsWfyiuMxyh7zOQzgMOiaSShd82CzucejJZ3AS4ysy4pjFNEaqBJk2DkSPjsM3APjyNHVuxL\nN9kv7GS2rw7xV1gqh/MjjKm8oJRlfwEuSni9lDD+b1/gtYT5vwR+Ged4Rx11lItI7dCxo3v4qi06\ndewYb/snn3Rv2LDotg0bhvnp2D7T8RcgYZz68qZM1mG0p+hQjAXDSJY2v0RmNtLMZpnZrPXr16ck\nUBFJjWR+IX/+ecXmFzd2LOzcWXTezp1hfjq2z3T8lVHjK73dfby757h7Tps2se5uF5EqkskimYNL\nGWC3tPnFJfuFnez2mY6/MjKZMFZRdFzjgnGHS5svIlUsk1/4yf5CvuMOaNiw6LyGDcP8OJL9wk52\n+0zHXylxy64qM1F2HcZZwHTCYO7HAO9H8+sSxkboRBjbeC7QNc7xVIchEl+my+DNSt7erGLvoWPH\nsE3HjhUrv890HUam4y9ABeowUpksJgNrCKOnrQR+AowCRkXLjdAa6hPC2MY5CdueSRib9xNgbNxj\nKmFIbZPMF06mv/CTPX5VSOb8VcX2yaqK41ckYexTAyjl5OS4equV2qKgSCixWKdhQxg/HoYNK3/7\nrKzwFV2cGeTnl799dnYohiquY0fIzS1/+2Tjl6phZrPdPSfOujW+0luktkq2DiDTZfDDhoXk0LFj\nSFIdOypZVHdKGCI1VLKtZKrDF/6wYeFqJD8/PCpZVG9KGCIZlEwrpWSvEPSFLxWlhCGSIck2S032\nCgH0hS8Vo4QhkoRkrhCSrYNQHYCkm1pJiVRSplspiVQFtZISSYNMt1ISSTclDJFKynQrJZF0U8IQ\nqaTq0EpJJJ2UMKRWS6bSWq2UpLZRwpBaK9lmrbpCkNpGraSk1kq2LySRfYFaSYnEkIkBaERqMiUM\nqdEy2bWGSG2jhCE1VnXoWkOkNlHCkBpLXWuIpJcqvaXGUtcaIslTpbfUCqqDEEkvJQypsVQHIZJe\nShhSY6kOQiS9lDAko5JpFgvqWkMknepmOgCpvYqPJ1HQLBb0xS9SHekKQzIm2WaxIpJeShiSMeqa\nQ6RmUcKQjFGzWJGaRQlDkpLp8SREJH2UMKTSNJ6ESO2irkGk0jSehEjNp65BJC1UaS1SuyhhSKWp\n0lqkdlHCkEpTpbVI7aKEIZWmSmuR2kVdg0hShg1TghCpLXSFISIisShhiIhILEoYIiISixJGLZfs\neBQiUnuo0rsW03gUIlIRKb3CMLOBZrbUzJab2ZgSlrcws2lmNs/M3jezbgnLcs1svpnNMTP195EC\nGo9CRCoiZVcYZlYHeBA4FVgJfGBmL7n7ooTVbgHmuPsQMzsiWn9AwvL+7r4hVTHWduraQ0QqIpVX\nGH2A5e6+wt2/A6YAg4ut0wX4J4C7LwGyzaxtCmOSBOraQ0QqIpUJoz3wRcLrldG8RHOBcwDMrA/Q\nEegQLXPgDTObbWYjSzuImY00s1lmNmv9+vVVFnxtoK49RKQiMt1K6k6guZnNAa4BPgJ2R8uOc/ee\nwBnAVWZ2Qkk7cPfx7p7j7jlt2rRJS9D7CnXtISIVkcpWUquAgxJed4jmFXL3rcBwADMz4FNgRbRs\nVfT4pZlNIxRxzUhhvLWSuvYQkbhSeYXxAXCYmXUys/rAUOClxBXMrHm0DGAEMMPdt5pZIzNrEq3T\nCDgNWJDCWGss3UchIumSsisMd88zs6uB14A6wKPuvtDMRkXLHwI6A4+bmQMLgZ9Em7cFpoWLDuoC\nT7n7q6mKtabSfRQikk4aorUG0xCpIpIsDdFaS+g+ChFJJyWMGkz3UYhIOilh1GC6j0JE0kkJowbT\nfRQikk7qrbaG030UIpIuusIQEZFYlDBERCQWJQwREYlFCUNERGJRwhARkViUMEREJBYlDBERiUUJ\nQ0REYlHCEBGRWJQwREQkFiWMDNOIeSJSU6gvqQzSiHkiUpPoCiODxo7dkywK7NwZ5ouIVDdKGBmk\nEfNEpCZRwsggjZgnIjWJEkYGacQ8EalJlDAySCPmiUhNolZSGaYR80SkptAVhoiIxKKEISIisShh\niIhILOUmDDO7xsxapCMYERGpvuJcYbQFPjCzqWY20Mws1UGJiEj1U27CcPdbgcOAvwJXAMvM7H/M\n7JAUxyYiItVIrDoMd3dgbTTlAS2AZ83srhTGJiIi1Ui592GY2XXAZcAG4BHgJnffZWZZwDLgv1Mb\nooiIVAdxbtxrCZzj7p8lznT3fDP7UWrCEhGR6iZOkdR0YFPBCzNramZHA7j74lQFJiIi1UuchDEO\n2J7wens0T0REapE4CcOiSm8gFEWhPqhERGqdOAljhZlda2b1ouk6YEWqA6spNCa3iNQWcRLGKKAf\nsApYCRwNjExlUDVFwZjcn30G7nvG5FbSEJF9kSWUNtV4OTk5PmvWrLQdLzs7JIniOnaE3Ny0hSEi\nUmlmNtvdc+KsG6cvqQZmdpWZ/dnMHi2YYgYy0MyWmtlyMxtTwvIWZjbNzOaZ2ftm1i3uttWBxuQW\nkdokTpHUE0A74HTg30AHYFt5G5lZHeBB4AygC3CRmXUpttotwBx37064OfBPFdg24zQmt4jUJnES\nxqHu/itgh7s/DpxFqMcoTx9gubuvcPfvgCnA4GLrdAH+CeDuS4BsM2sbc9uM05jcIlKbxEkYu6LH\nr6Iio2bAATG2aw98kfB6ZTQv0VzgHAAz6wN0JFzBxNmWaLuRZjbLzGatX78+RlhVR2Nyi0htEud+\nivHReBi3Ai8BjYFfVdHx7wT+ZGZzgPnAR8DuiuzA3ccD4yFUeldRXLFpTG4RqS3KTBhRB4Nb3X0z\nMAP4fgX2vQo4KOF1h2heIXffCgyPjmXAp4R7PPYvb1sREUmvMoukoru6K9sb7QfAYWbWyczqA0MJ\nVyiFzKx5tAxgBDAjSiLlbisiIukVp0jqDTO7EXga2FEw0903lb4JuHuemV0NvAbUAR5194VmNipa\n/hDQGXjczBxYCPykrG0r/O5ERKTKlHvjnpl9WsJsd/eKFE+lRbpv3BMRqekqcuNeuVcY7t4p+ZCk\nNNu2wdixsHYtfO97cOCBex4LnjdvHlphiYhkUpwR9y4rab67T6z6cGqXjz+GIUNgyRI49FB49dWQ\nQIpr0KD0ZFLw2KEDNG2qxCIiqROnDuOHCc8bAAOADwEljCT87W9wySVQvz784x9w8slh/vbtsGZN\nmFavDlPB8zVrYP58eP112Lp17302bgwHHRSSR+Jj4vOmTdP7PkVk3xGnSOqaxNdm1pxw57VUQn4+\n3H47/Pa3cNRR8Nxz4Ya/Ao0bw2GHhaksxRPLypVh+uKL8LhgQSjmKl5F1aTJ3kmkQ4eQsDqp8FFE\nylCZgZB2APpqqYSvvoJLL4W//x2uuAL+/GfYf//K7StOYvnuu5BQCpJI4uMXX8DcuSGpANSpA5dd\nBrfcEorHRESKi1OH8Teg4HdqFqH/p6mpDGpftHBhqK/49FN48EEYPTr19Q3164erl8QrmOK++y7E\nNG4c/OUv8Pjj4c71W2+FH/wgtfGJSM0Sp1ntiQkv84DP3H1lSqOqpOrarPbZZ8MVRZMm8MwzcNxx\nmY6oZGvXwt13hyufb7+FoUND4ujcOdORiUiqVOl4GMDnwHvu/m93/3/ARjPLTiK+WmP3bhgzBs4/\nH7p3h9mzq2+yAGjXLiSM3Fy48UZ48UXo2jUkjgULqv547qGl2F//Cq+9Fup3RKT6ipMwngES/5V3\nR/OkDBs3wsCB8Ic/wKhR8K9/hSawNcEBB4S4c3Phl7+EV16BI48MiW/evMrv1x0++QQeeSS0EOvQ\nAQ4/HEaMCOeqW7ew7JtvquytiEgVipMw6kZjUgAQPa9fxvq13kcfhRZQM2aEX8/jxoX6hJqmdesw\ntkduLvzqV6E5b48eoS7mo4/i7SM3FyZMCBXqHTuGCvWf/hTeeANOOCHUmyxaBE8+Ge43+elPwwBU\nt90GX36ZwjcnIhXn7mVOwD+AQQmvBwNvlrddJqajjjrKM23iRPcGDdw7dHB///1MR1O1Nm1yv+02\n9+bN3cH9xz92/+CDout8/rn744+7X3GFe3Z2WA/c27RxP/989z//2X3RIvf8/L33n5/v/tZbYb/g\nvt9+7iNGuC9cmJa3J1IrAbM85ndsnErvQ4BJQEGBykrgMndfnqokVlmZrPTetSuU+993H5x0Ejz9\ndCja2Rdt2QIPPAD33AObNsGZZ4a7zd96C1asCOu0agUnngj9+4epS5eKtQpbuhTuvRceeywUUQ0c\nCL/4BQwYUPWty9avh82bISsr7DvxsaR5Ja3TqFFomixS01Sk0rvchJGw08YA7r49idhSKlMJY906\nuOCCUAT185/DXXdB3crc4VLDbNsWmgj/8Y+hgv/EE0Oy7N8/1EdkxSnwLMeGDfDQQyFBrVsXGg/c\ncEOoiN9vv4rta+fOUPw1f/6ead68qin62m+/UNx2+OF7Ty1aJL9/kVSp0oRhZv8D3OXuX0WvWwC/\ncPdbk460imUiYbzzTqgM3rQpVNhefHFaD18tFLRuqooEUZpvv4WnngpXNQsWhBZdV18dGhS0alV0\n3d27w5VOYlKYPx+WL99z53uDBqEF2JFHhumAAwoKz8L7Keux+Lz8/JDMli4N/YJ98gnk5e2Jp02b\nognkiCPCY6dOUK9e6s6ZSBxVnTA+cvdexeZ96O69k4gxJdKZMNxDZfb114fuNZ5/PlQIS2q5hwrz\nP/4xNMXdf/9wj8thh+1JEAsXwtdfh/XNwi//gsRQMB1ySOqKkHbtCjdDLl1adFqyJBR/FahbN8Rx\n+OEhYZVX9FXWY+vWodivS5fQ+kydUEpcVZ0w5gE/dPdvo9f7EypJuiYdaRVLV8LYuTP8sn3iCTjr\nrPCoYof0W7AA/vd/Qwur774LX7rFE0OXLqF+obrYvHnvRLJ0abhCjXN1U9JjwVSgSZM9ySNxOvjg\n1F4FSs1U1QnjZuDHwATAgCuAl9z9riTjrHLpSBiffALnnBN+yf72t2EsC/0TZtbmzeFX/b7ayCCO\n9eth8eJQR7NoUbjKWrRoT19hAA0bhrv2u3Ytmkiys1VhX5tVeaW3mQ0ETiH0KbUVaOfuVyUVZQqk\nOmH8/e/hhrOsrFCePnBgyg4lUiU2bSqaSAqmlQmd+zRoEIpVmzWr3NSgQebenySvSkfci6wjJIvz\ngU+B5yoZW420e3e4mvjd76BXr9AluboCl5qgZUs49tgwJdqyJdSpLFwYplWrwrwtW0IPxwXPt8do\nE1nQyeUxx0DfvtCvX2gll46rFvfQ4GD79tCTQsOGqT9mbVZqwjCzHwAXRdMG4GnCFUn/NMVWLWzc\nGHpvfe01GD48NCOtbJfkItVFs2Zw9NFhKsvu3WGwroIEUtL01VehT7DXXgv1eRC63+/TJySQvn1D\nMinemq2iduwIya1467cNG/as07w5tG+/99Shw57nrVurGLmyyrrCWALMBH5UcJOemf08LVFVEx9+\nCOeeGwYoGj8+9Hmk1idSm9SpExp0xGnU4R6aM7/zzp7pzjtD0oHQGqwggfTrF+pPSvrizssLTaAT\n75eZPz/su6AEvWHDcBVz9tmhcUPz5uEqKXEqGESseKeW9eqFq5HEhHLYYSGpde9eO+6hqqxS6zDM\n7GxgKHAs8CphlL1H3L3aFsZUZR3GhAlhzIoDDghFUD/8YfnbiEhRO3bABx/sSSBvvx2u2iEMF3z0\n0SGBNG26JzEsWrSnA8qsrPBl3r170dZvnTrFu0rIywtFVqtWhXqb4kmlYNqxI6zfsGH4Xy9Iascc\nE+6j2ZdVdSupRoT+oy4CTiaM5T3N3V9PNtCqVhUJ49tv4dprwxXFKafA5MnhElZEkucerh4Sr0Lm\nzw9XAe3ahWSQmBw6d059EbA7fP550Zg++mjPzZeHHrrnyqhv33Blsy9dhaSka5Boxy0IFd8XuvuA\nSsaXMskmjM8/h/POC7+IfvnLUMmt5oYiqbVtW/ihVp1+mH39NcyaVTSJrFsXljVqtKd+puAqJNn6\nmYrasSMUtxVM335b+V4mUpYwqrtkEsYbb4T+iXbtgokTYfDgKg5ORGos99BVf2LR2ty5e+pnDjxw\nT11PixahTiXxsbR5jRrtqRfNywv9miUmgrVrQ6u14vOKt15r3bpoLwIVkYpmtfus/PwwWFDBUKTP\nP6+xrEWkKLNQb9Kp055f8jt27LkK+fjj0Fps8+ZQUjFvXni+dWvZ+61bNyQQs9Daq6Tf782bh+K6\ndu0gJ2fP8+JTOtT6K4zNm0OZ6fHHw8MPV69uJESkZtu9e0/T482bS3/Mzw9DBBRPAm3bpv7GSF1h\nVECLFvD+++GPoyazIlKV6tQJN0+2bJnpSKpGrU8YEDK7iIiUTfc7iohILEoYIiISixKGiIjEooQh\nIiKxKGGIiEgsShgiIhKLEoaIiMSihCEiIrEoYYiISCwpTRhmNtDMlprZcjMbU8LyZmb2NzOba2YL\nzWx4wrJcM5tvZnPMrGpGRRIRkUpLWdcgZlYHeBA4FVgJfGBmL7n7ooTVrgIWufuPzawNsNTMJrn7\nd9Hy/u6+ARERybhUXmH0AZa7+4ooAUwhjNyXyIEmZmZAY2ATkJfCmEREpJJSmTDaA18kvF4ZzUv0\nANAZWA3MB65z94Ih2x14w8xmm9nI0g5iZiPNbJaZzVpf2RFERESkXJmu9D4dmAMcCPQEHjCzptGy\n49y9J3AGcJWZnVDSDtx9vLvnuHtOm319tHYRkQxKZcJYBRyU8LpDNC/RcOB5D5YDnwJHALj7qujx\nS2AaoYhLREQyJJUJ4wPgMDPrZGb1gaHAS8XW+RwYAGBmbYHDgRVm1sjMmkTzGwGnAQtSGKuIiJQj\nZa2k3D3PzK4GXgPqAI+6+0IzGxUtfwj4HfCYmc0HDLjZ3TeY2feBaaEunLrAU+7+aqpiFRGR8tX6\nMb1FRGqziozpnelKbxERqSGUMEREJBYlDBERiUUJQ0REYlHCEBGRWJQwREQkFiUMERGJRQlDRERi\nUcIQEZFYlDBERCQWJQwREYlFCUNERGJRwhARkViUMEREJBYlDBERiUUJQ0REYlHCEBGRWJQwREQk\nFiUMERGJRQlDRERiUcIQEZFYlDBERCQWJQwREYmlbqYDEJGqtWvXLlauXMk333yT6VCkGmnQoAEd\nOnSgXr16ld6HEobIPmblypU0adKE7OxszCzT4Ug14O5s3LiRlStX0qlTp0rvR0VSIvuYb775hlat\nWilZSCEzo1WrVklfdSphiOyDlCykuKr4TChhiIhILEoYIrXcpEmQnQ1ZWeFx0qTk9rdx40Z69uxJ\nz549adeuHe3bty98/d1338Xax/Dhw1m6dGmZ6zz44INMSjbYBOvWraNu3bo88sgjVbbPfY25e6Zj\nqDI5OTk+a9asTIchklGLFy+mc+fOsdadNAlGjoSdO/fMa9gQxo+HYcOSj+W2226jcePG3HjjjUXm\nuzvuTlZW9fnNev/99zN16lTq16/Pm2++mbLj5OXlUbduZtoblfTZMLPZ7p4TZ/vq89cSkbQbO7Zo\nsoDweuzYqj/W8uXL6dKlC8OGDaNr166sWbOGkSNHkpOTQ9euXbn99tsL1z3uuOOYM2cOeXl5NG/e\nnDFjxtCjRw/69u3Ll19+CcCtt97KvffeW7j+mDFj6NOnD4cffjhvv/02ADt27ODcc8+lS5cunHfe\neeTk5DBnzpwS45s8eTL33nsvK1asYM2aNYXzX375ZXr37k2PHj047bTTANi2bRuXX3453bt3p3v3\n7rzwwguFsRaYMmUKI0aMAOCSSy5h9OjR9OnTh1tuuYV3332Xvn370qtXL4499liWLVsGhGTy85//\nnG7dutG9e3f+/Oc/8/rrr3PeeecV7nf69Omcf/75Sf89KkPNakVqsc8/r9j8ZC1ZsoSJEyeSkxN+\n0N555520bNmSvLw8+vfvz3nnnUeXLl2KbLNlyxZOPPFE7rzzTm644QYeffRRxowZs9e+3Z3333+f\nl156idtvv51XX32V+++/n3bt2vHcc88xd+5cevfuXWJcubm5bNq0iaOOOorzzz+fqVOnct1117F2\n7VpGjx7NzJkz6dixI5s2bQLClVObNm2YN28e7s5XX31V7ntfs2YN7777LllZWWzZsoWZM2dSt25d\nXn31VW699Vaefvppxo0bx+rVq5k7dy516tRh06ZNNG/enKuvvpqNGzfSqlUrJkyYwJVXXlnRU18l\ndIUhUosdfHDF5ifrkEMOKUwWEH7V9+7dm969e7N48WIWLVq01zb7778/Z5xxBgBHHXUUubm5Je77\nnHPO2WtYjNBSAAAQ2klEQVSd//znPwwdOhSAHj160LVr1xK3nTJlChdeeCEAQ4cOZfLkyQC88847\n9O/fn44dOwLQsmVLAN544w2uuuoqILQ+atGiRbnv/fzzzy8sgvvqq68499xz6datGzfeeCMLFy4s\n3O+oUaOoU6dO4fGysrIYNmwYTz31FJs2bWL27NmFVzrppisMkVrsjjtKrsO4447UHK9Ro0aFz5ct\nW8af/vQn3n//fZo3b84ll1xS4n0C9evXL3xep04d8vLyStz3fvvtV+46pZk8eTIbNmzg8ccfB2D1\n6tWsWLGiQvvIysoisU64+HtJfO9jx47l9NNP57/+679Yvnw5AwcOLHPfV155Jeeeey4AF154YWFC\nSTddYYjUYsOGhQrujh3BLDxWVYV3ebZu3UqTJk1o2rQpa9as4bXXXqvyYxx77LFMnToVgPnz55d4\nBbNo0SLy8vJYtWoVubm55ObmctNNNzFlyhT69evHW2+9xWeffQZQWCR16qmn8uCDDwKhKGzz5s1k\nZWXRokULli1bRn5+PtOmTSs1ri1bttC+fXsAHnvsscL5p556Kg899BC7d+8ucryDDjqI1q1bc+ed\nd3LFFVckd1KSoIQhUssNGwa5uZCfHx7TkSwAevfuTZcuXTjiiCO47LLLOPbYY6v8GNdccw2rVq2i\nS5cu/Pa3v6VLly40a9asyDqTJ09myJAhReade+65TJ48mbZt2zJu3DgGDx5Mjx49GBadnN/85jes\nW7eObt260bNnT2bOnAnAH/7wB04//XT69etHhw4dSo3r5ptv5qabbqJ3795Frkp+9rOf0a5dO7p3\n706PHj0Kkx3AxRdfTKdOnfjBD36Q9HmpLDWrFdnHVKRZ7b4uLy+PvLw8GjRowLJlyzjttNNYtmxZ\nxpq1JmPUqFH07duXyy+/vNL7SLZZbc07ayIiMW3fvp0BAwaQl5eHu/OXv/ylRiaLnj170qJFC+67\n776MxpHSM2dmA4E/AXWAR9z9zmLLmwFPAgdHsdzt7hPibCsiUp7mzZsze/bsTIeRtNLuHUm3lNVh\nmFkd4EHgDKALcJGZdSm22lXAInfvAZwE/NHM6sfcVkRE0iiVld59gOXuvsLdvwOmAIOLreNAEwvd\nKDYGNgF5MbcVEZE0SmXCaA98kfB6ZTQv0QNAZ2A1MB+4zt3zY24LgJmNNLNZZjZr/fr1VRW7iIgU\nk+lmtacDc4ADgZ7AA2bWtCI7cPfx7p7j7jlt2rRJRYwiIkJqE8Yq4KCE1x2ieYmGA897sBz4FDgi\n5rYiUg31799/r5vw7r33XkaPHl3mdo0bNwbCXdaJne0lOumkkyiv6fy9997LzoRb188888xYfT3F\n1bNnz8LuRmqbVCaMD4DDzKyTmdUHhgIvFVvnc2AAgJm1BQ4HVsTcVkSqoYsuuogpU6YUmTdlyhQu\nuuiiWNsfeOCBPPvss5U+fvGE8corrxTpRTYZixcvZvfu3cycOZMdO3ZUyT5LUtGuTdIlZQnD3fOA\nq4HXgMXAVHdfaGajzGxUtNrvgH5mNh94E7jZ3TeUtm2qYhXZV11/PZx0UtVO119f9jHPO+88Xn75\n5cLBknJzc1m9ejXHH3984X0RvXv35sgjj+TFF1/ca/vc3Fy6desGwNdff83QoUPp3LkzQ4YM4euv\nvy5cb/To0YVdo//mN78B4L777mP16tX079+f/v37A5Cdnc2GDRsAuOeee+jWrRvdunUr7Bo9NzeX\nzp0789Of/pSuXbty2mmnFTlOosmTJ3PppZdy2mmnFYl9+fLlnHLKKfTo0YPevXvzySefAOHO7yOP\nPJIePXoU9rCbeJW0YcMGsrOzgdBFyKBBgzj55JMZMGBAmedq4sSJhXeDX3rppWzbto1OnTqxa9cu\nIHS7kvi6qqT0Pgx3fwV4pdi8hxKerwZK7HaxpG1FpPpr2bIlffr0Yfr06QwePJgpU6ZwwQUXYGY0\naNCAadOm0bRpUzZs2MAxxxzDoEGDSh1vety4cTRs2JDFixczb968It2T33HHHbRs2ZLdu3czYMAA\n5s2bx7XXXss999zDW2+9RevWrYvsa/bs2UyYMIH33nsPd+foo4/mxBNPLOz/afLkyTz88MNccMEF\nPPfcc1xyySV7xfP000/zj3/8gyVLlnD//fdz8cUXAzBs2DDGjBnDkCFD+Oabb8jPz2f69Om8+OKL\nvPfeezRs2LCwX6iyfPjhh8ybN6+wy/eSztWiRYv4/e9/z9tvv03r1q3ZtGkTTZo04aSTTuLll1/m\n7LPPZsqUKZxzzjnUq1evIn+6ctW8Wx5FJLboR3TaFRRLFSSMv/71r0DoqO+WW25hxowZZGVlsWrV\nKtatW0e7du1K3M+MGTO49tprAQoHKyowdepUxo8fT15eHmvWrGHRokVFlhf3n//8hyFDhhT2GnvO\nOecwc+ZMBg0aRKdOnejZsydQehfqs2bNonXr1hx88MG0b9+eK6+8kk2bNlGvXj1WrVpV2B9VgwYN\ngNBV+fDhw2nYsCGwp2v0spx66qmF65V2rv75z39y/vnnFybEgvVHjBjBXXfdxdlnn82ECRN4+OGH\nyz1eRWW6lVTGVfV4xiICgwcP5s033+TDDz9k586dHHXUUQBMmjSJ9evXM3v2bObMmUPbtm1L7NK8\nPJ9++il33303b775JvPmzeOss86q1H4KFHSNDqV3jz558mSWLFlCdnY2hxxyCFu3buW5556r8LHq\n1q1Lfn4+UHYX6BU9V8ceeyy5ubn861//Yvfu3YXFelWpVieMgvGMP/sM3MPjyJFKGiLJaty4Mf37\n9+fKK68sUtm9ZcsWDjjgAOrVq1ek2/DSnHDCCTz11FMALFiwgHnz5gGhjL5Ro0Y0a9aMdevWMX36\n9MJtmjRpwrZt2/ba1/HHH88LL7zAzp072bFjB9OmTeP444+P9X7y8/OZOnUq8+fPL+wC/cUXX2Ty\n5Mk0adKEDh068MILLwDw7bffsnPnTk499VQmTJhQWAFfUCSVnZ1d2F1JWZX7pZ2rk08+mWeeeYaN\nGzcW2S/AZZddxsUXX8zw4cNjva+KqtUJI53jGYvUNhdddBFz584tkjCGDRvGrFmzOPLII5k4cSJH\nHHFEmfsYPXo027dvp3Pnzvz6178uvFLp0aMHvXr14ogjjuDiiy8u0jX6yJEjGThwYGGld4HevXtz\nxRVX0KdPH44++mhGjBhBr169Yr2XmTNn0r59ew488MDCeSeccAKLFi1izZo1PPHEE9x33310796d\nfv36sXbtWgYOHMigQYPIycmhZ8+e3H333QDceOONjBs3jl69ehVWxpektHPVtWtXxo4dy4knnkiP\nHj244YYbimyzefPm2C3SKqpWd2+elRWuLIozC2MDiNRE6t689nr22Wd58cUXeeKJJ0pcru7Nk3Dw\nwaEYqqT5IiI1yTXXXMP06dN55ZXUNS6t1Qkj3eMZi4ikyv3335/yY9TqOoxMjmcskkr7UlGzVI2q\n+EzU6isMCMlBCUL2JQ0aNGDjxo20atWq1BvipHZxdzZu3Fh4j0hl1fqEIbKv6dChAytXrkTd/Uui\nBg0a0KFDh6T2oYQhso+pV68enTp1ynQYsg+q1XUYIiISnxKGiIjEooQhIiKx7FN3epvZeqDszmky\npzVQej8Amaf4kqP4kqP4kpNMfB3dPdb41vtUwqjOzGxW3NvvM0HxJUfxJUfxJSdd8alISkREYlHC\nEBGRWJQw0md8pgMoh+JLjuJLjuJLTlriUx2GiIjEoisMERGJRQlDRERiUcKoQmZ2kJm9ZWaLzGyh\nmV1XwjonmdkWM5sTTb9Oc4y5ZjY/OvZewxNacJ+ZLTezeWbWO42xHZ5wXuaY2VYzu77YOmk9f2b2\nqJl9aWYLEua1NLN/mNmy6LFFKdsONLOl0bkck8b4/q+ZLYn+ftPMrHkp25b5WUhhfLeZ2aqEv+GZ\npWybqfP3dEJsuWY2p5Rt03H+SvxOydhn0N01VdEEfA/oHT1vAnwMdCm2zknA3zMYYy7QuozlZwLT\nAQOOAd7LUJx1gLWEm4oydv6AE4DewIKEeXcBY6LnY4A/lBL/J8D3gfrA3OKfhRTGdxpQN3r+h5Li\ni/NZSGF8twE3xvj7Z+T8FVv+R+DXGTx/JX6nZOozqCuMKuTua9z9w+j5NmAx0D6zUVXYYGCiB+8C\nzc3sexmIYwDwibtn9M59d58BbCo2ezDwePT8ceDsEjbtAyx39xXu/h0wJdou5fG5++vunhe9fBdI\nrk/rJJRy/uLI2PkrYGEwkQuAyVV93LjK+E7JyGdQCSNFzCwb6AW8V8LiflFxwXQz65rWwMCBN8xs\ntpmNLGF5e+CLhNcryUzSG0rp/6iZPH8Abd19TfR8LdC2hHWqy3m8knDFWJLyPgupdE30N3y0lOKU\n6nD+jgfWufuyUpan9fwV+07JyGdQCSMFzKwx8BxwvbtvLbb4Q+Bgd+8O3A+8kObwjnP3nsAZwFVm\ndkKaj18uM6sPDAKeKWFxps9fER6u/atl23QzGwvkAZNKWSVTn4VxhGKSnsAaQrFPdXQRZV9dpO38\nlfWdks7PoBJGFTOzeoQ/7CR3f774cnff6u7bo+evAPXMrHW64nP3VdHjl8A0wmVrolXAQQmvO0Tz\n0ukM4EN3X1d8QabPX2RdQTFd9PhlCetk9Dya2RXAj4Bh0RfKXmJ8FlLC3de5+253zwceLuW4mT5/\ndYFzgKdLWydd56+U75SMfAaVMKpQVOb5V2Cxu99TyjrtovUwsz6Ev8HGNMXXyMyaFDwnVI4uKLba\nS8BlUWupY4AtCZe+6VLqL7tMnr8ELwGXR88vB14sYZ0PgMPMrFN0xTQ02i7lzGwg8N/AIHffWco6\ncT4LqYovsU5sSCnHzdj5i5wCLHH3lSUtTNf5K+M7JTOfwVTW8Ne2CTiOcGk4D5gTTWcCo4BR0TpX\nAwsJLRbeBfqlMb7vR8edG8UwNpqfGJ8BDxJaV8wHctJ8DhsREkCzhHkZO3+ExLUG2EUoA/4J0Ap4\nE1gGvAG0jNY9EHglYdszCa1aPik412mKbzmh7LrgM/hQ8fhK+yykKb4nos/WPMIX2Peq0/mL5j9W\n8JlLWDcT56+075SMfAbVNYiIiMSiIikREYlFCUNERGJRwhARkViUMEREJBYlDBERiUUJQ6QcZrbb\nivaiW2U9p5pZdmJPqSLVWd1MByBSA3ztoQsIkVpNVxgilRSNh3BXNCbC+2Z2aDQ/28z+GXWu96aZ\nHRzNb2thfIq50dQv2lUdM3s4Gu/gdTPbP1r/2mgchHlmNiVDb1OkkBKGSPn2L1YkdWHCsi3ufiTw\nAHBvNO9+4HEPHSROAu6L5t8H/NvdexDGYFgYzT8MeNDduwJfAedG88cAvaL9jErVmxOJS3d6i5TD\nzLa7e+MS5ucCJ7v7iqiDuLXu3srMNhC6u9gVzV/j7q3NbD3Qwd2/TdhHNvAPdz8sen0zUM/df29m\nrwLbCT3yvuBRp4simaIrDJHkeCnPK+LbhOe72VO3eBahX6/ewAdRD6oiGaOEIZKcCxMe34mev03o\nGRRgGDAzev4mMBrAzOqYWbPSdmpmWcBB7v4WcDPQDNjrKkcknfSLRaR8+5vZnITXr7p7QdPaFmY2\nj3CVcFE07xpggpndBKwHhkfzrwPGm9lPCFcSowk9pZakDvBklFQMuM/dv6qydyRSCarDEKmkqA4j\nx903ZDoWkXRQkZSIiMSiKwwREYlFVxgiIhKLEoaIiMSihCEiIrEoYYiISCxKGCIiEsv/B0++xNRW\n6upkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a221e8390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's unpack the plots above. The training loss decreases with every epoch, while the training accuracy increases with every epoch, which is what we would expect to happen with gradient descent. The validation loss and accuracy do not show the same trends, however. The validation loss seems to hit its lowest point around 4 epochs, and the validation accuracy peaks at around the same 4th epoch. What we are seeing here is a case of *overfitting*. We ended up learning representations that are specific to the training data, but don't generalize well to data outside of the training set.\n",
    "\n",
    "Let's train a new network from scratch using four epochs and then evaluate it on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.4704 - acc: 0.8107     \n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.2649 - acc: 0.9076     \n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.2023 - acc: 0.9275     \n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.1687 - acc: 0.9403     - ETA: 1s -\n",
      "24864/25000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29129809645652771, 0.88548000000000004]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this fairly naive approach, we achieved an accuracy of 88%. With state-of-the-art approaches, we should be able to get close to 95%.\n",
    "\n",
    "### 3.4.5 Using a trained network to generate predictions on new data\n",
    "After training a network, we'll want to use it in a practical setting, so we will generate the likelihood of reviews being positive by using the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.92421025],\n",
       "       [ 0.83551949],\n",
       "       [ 0.99949062],\n",
       "       ..., \n",
       "       [ 0.44672826],\n",
       "       [ 0.0036482 ],\n",
       "       [ 0.81084663]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers above indicate percentages indicating a confidence level for positive (closer to 1) and negative reviews (closer to 0). We also see that the network is not extremely confident in its classification on samples where the predictions are around 0.4 or 0.6.\n",
    "\n",
    "### 3.4.6 Further experiments\n",
    "\n",
    "### Using three hidden layers instead of two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.4772 - acc: 0.7932     \n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.2578 - acc: 0.9100     \n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.1960 - acc: 0.9288     \n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 2s - loss: 0.1710 - acc: 0.9365     \n",
      "25000/25000 [==============================] - 5s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30483594050407409, 0.88131999999999999]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy went down from 88.5% to 88.1%**\n",
    "\n",
    "### Changing the number of hidden units from 16 to 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 6s - loss: 0.4297 - acc: 0.8250     \n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.2443 - acc: 0.9103     \n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.1897 - acc: 0.9298     \n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.1573 - acc: 0.9421     \n",
      "24928/25000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3116677111721039, 0.87927999999999995]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy went down from 88.5% to 87.9%**\n",
    "\n",
    "### Changing the number of hidden units from 16 to 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 8s - loss: 0.4196 - acc: 0.8129     - ETA: 5s\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 5s - loss: 0.2372 - acc: 0.9091     - ETA: 3s\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 4s - loss: 0.1829 - acc: 0.9300     \n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 4s - loss: 0.1416 - acc: 0.9478     \n",
      "24960/25000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3292320645189285, 0.87716000000000005]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy went down from 88.5% to 87.1%**\n",
    "\n",
    "### Using the `mse` loss function instead of `binary_crossentropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 5s - loss: 0.1482 - acc: 0.8204     \n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.0764 - acc: 0.9121     \n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.0580 - acc: 0.9312     \n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.0482 - acc: 0.9438     \n",
      "24864/25000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.086584766408205033, 0.88180000000000003]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy went down from 88.5% to 88.2%**\n",
    "\n",
    "### Using the `tanh` activation instead of `relu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 5s - loss: 0.4294 - acc: 0.8306     \n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.2376 - acc: 0.9129     \n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.1793 - acc: 0.9346     \n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 3s - loss: 0.1479 - acc: 0.9457     \n",
      "24992/25000 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3313264957141876, 0.87536000000000003]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='tanh', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy went down from 88.5% to 87.5%**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
